{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fogg-lab/tissue-model-analysis-tools/blob/main/notebooks/microvessels_segmentation_training/train_binary_segmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3YkTJ-cx1qb5"
      },
      "source": [
        "# Train Binary Segmentation\n",
        "## Instructions to run\n",
        "- If you're running this notebook in Colab, run the first section (Environment setup) to install the packages\n",
        "- Edit the configuration variables in the [Constants](#constants) section and the [Training configuration](#training-configuration) section as needed.\n",
        "- Customize the image transformations pipeline in the [Image transformations and augmentation](#image-transformations-and-augmentation) section as needed.\n",
        "- Run all the cells\n",
        "- *Note*: It is recommended to run this notebook on a system with a CUDA-capable GPU, but if you want to try training on Colab, you can use a GPU runtime and use this trick to keep the runtime alive: https://stackoverflow.com/a/59226569"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wH2fq4jL71Oj"
      },
      "source": [
        "## Environment setup (for Colab)\n",
        "**If you are not in Colab, follow the installation instructions in the README.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Not in Google Colab. Skipping environment setup.\n"
          ]
        }
      ],
      "source": [
        "def in_colab() -> bool:\n",
        "    \"\"\"Check if the code is running in Google Colab.\"\"\"\n",
        "    try:\n",
        "        import google.colab\n",
        "        return True\n",
        "    except ImportError:\n",
        "        return False\n",
        "\n",
        "if in_colab():\n",
        "    !pip install albumentations\n",
        "    !pip install boost\n",
        "    !pip install dask\n",
        "    !pip install gudhi\n",
        "    !pip install jupyterlab\n",
        "    !pip install matplotlib\n",
        "    !pip install networkx\n",
        "    !pip install opencv-python\n",
        "    !pip install scikit-learn\n",
        "    !pip install scipy\n",
        "    !pip install setuptools\n",
        "    !pip install keras-tuner\n",
        "    !pip install pillow\n",
        "    !pip install scikit-image\n",
        "    !pip install tqdm\n",
        "    !pip install imagecodecs\n",
        "    !pip install pandas\n",
        "    !pip install \"tensorflow[and-cuda]\"\n",
        "\n",
        "    # Install the fl_tissue_model_tools (tmat) package\n",
        "    !pip install -I fl_tissue_model_tools@git+https://github.com/fogg-lab/tissue-model-analysis-tools.git#subdirectory=src\n",
        "\n",
        "    # Configure package home directory\n",
        "    !tmat configure /content/fl_tissue_model_tools\n",
        "else:\n",
        "    print('Not in Google Colab. Skipping environment setup.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NidaRMYh1v2U"
      },
      "source": [
        "## Import packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xFO20bfr1x8x"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import math\n",
        "import os\n",
        "import requests\n",
        "from zipfile import ZipFile\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import albumentations as A\n",
        "if not hasattr(Image, 'Resampling'):\n",
        "    Image.Resampling = Image\n",
        "\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
        "\n",
        "import tensorflow.keras.backend as K\n",
        "from tensorflow.config import list_physical_devices\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard, ReduceLROnPlateau, CSVLogger\n",
        "from tensorflow.keras.losses import BinaryCrossentropy\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.utils import custom_object_scope\n",
        "\n",
        "from fl_tissue_model_tools.transforms import get_elastic_dual_transform\n",
        "from fl_tissue_model_tools.preprocessing import get_batch_augmentor\n",
        "from fl_tissue_model_tools import models, models_util, defs\n",
        "from fl_tissue_model_tools.helper import get_img_mask_paths\n",
        "\n",
        "# Make sure TensorFlow is using GPU - print out the available GPUs\n",
        "available_gpus = list_physical_devices('GPU')\n",
        "if len(available_gpus) == 0:\n",
        "    print(\"WARNING: TensorFlow isn't using a GPU.\")\n",
        "else:\n",
        "    print(f\"Available GPUS:\\n{available_gpus}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kAu4-RcNHsJh"
      },
      "source": [
        "<a name=\"constants\"></a>\n",
        "## Constants"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZsraYg1EH0iN"
      },
      "outputs": [],
      "source": [
        "rand_seed = 1234\n",
        "\n",
        "batch_size = 8\n",
        "\n",
        "# size of the random crop window, cannot be larger than the image size\n",
        "crop_window = (512, 512)\n",
        "\n",
        "# model input shape. cropped images/masks are resampled to this shape\n",
        "# target_shape must be divisible by 32, and must be square if using the patch-blending segmentor\n",
        "target_shape = (320, 320)\n",
        "#target_shape = crop_window     # uncomment to disable resizing the crops\n",
        "\n",
        "training_dir = defs.MODEL_TRAINING_DIR / \"binary_segmentation\"\n",
        "experiment_number = models_util.get_last_exp_num() + 1\n",
        "checkpoint_save_path = training_dir / \"checkpoints\" / f\"checkpoint_{experiment_number}.h5\"\n",
        "log_dir = training_dir / f\"logs_{experiment_number}\"\n",
        "\n",
        "images_dir = os.path.join(training_dir, \"images\")\n",
        "labels_dir = os.path.join(training_dir, \"masks\")\n",
        "\n",
        "# number of times to iterate over the samples each epoch\n",
        "repeat_dset_n_times = 50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3hZ4rclKIItR"
      },
      "outputs": [],
      "source": [
        "# Create the training and directory if it doesn't exist\n",
        "Path(training_dir).mkdir(exist_ok=True)\n",
        "Path(log_dir).mkdir(exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kVgwB0JyZGdB"
      },
      "source": [
        "### Hyperparameter search space"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KBnYCIlVZDo3"
      },
      "outputs": [],
      "source": [
        "filter_counts_options = [\n",
        "    (16, 32, 64, 128),\n",
        "    (32, 64, 128, 256),\n",
        "    (64, 128, 256, 512)\n",
        "]\n",
        "\n",
        "# Scale learning rate options linearly according to batch size (stays as-is when batch size is 16)\n",
        "hp_search_initial_lr_options = [1e-4, 2.5e-4, 5e-4, 1e-3, 2.5e-3, 5e-3, 1e-2]\n",
        "hp_search_initial_lr_options = np.array(hp_search_initial_lr_options) * batch_size/16"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "otHVkJSCGd5l"
      },
      "source": [
        "## Download demo training dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LHtbr58qGY_u"
      },
      "outputs": [],
      "source": [
        "filename = \"branching_training_data.zip\"\n",
        "url = f\"https://github.com/fogg-lab/tissue-model-analysis-tools/raw/main/sample_data/{filename}\"\n",
        "data = requests.get(url).content\n",
        "archive_save_path = os.path.join(training_dir, filename)\n",
        "open(archive_save_path, 'wb').write(data)\n",
        "\n",
        "# Extract the archive\n",
        "with ZipFile(archive_save_path, 'r') as data_archive:\n",
        "    data_archive.extractall(training_dir)\n",
        "\n",
        "# Delete the archive\n",
        "os.remove(archive_save_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PjMqZzUHHeHu"
      },
      "source": [
        "## Validate data paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8gkO2tmaHbA5"
      },
      "outputs": [],
      "source": [
        "image_mask_paths = get_img_mask_paths(images_dir, labels_dir)\n",
        "img_paths, mask_paths = zip(*image_mask_paths)\n",
        "\n",
        "print(f\"Found {len(image_mask_paths)} image/label pairs\")\n",
        "\n",
        "for img_path, mask_path in image_mask_paths:\n",
        "    image = cv2.imread(img_path, 0)\n",
        "    mask = cv2.imread(mask_path, 0)\n",
        "\n",
        "    assert image.shape == mask.shape, (\n",
        "        f\"Image {img_path} and mask {mask_path} have different shapes: {image.shape} vs {mask.shape}\"\n",
        "    )\n",
        "\n",
        "    if np.unique(mask).tolist() not in ([0], [255], [0, 255]):\n",
        "        print(f\"Mask {mask_path} has unexpected values: {np.unique(mask)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BhfUwuluI2iZ"
      },
      "source": [
        "## Data pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hb-4-KtDMfAs"
      },
      "source": [
        "### Get training and validation image paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fo6FQg9XMeUJ"
      },
      "outputs": [],
      "source": [
        "n_val = int(len(img_paths) * 0.2)\n",
        "\n",
        "# Shuffle the data image/mask keeping pairs together\n",
        "\n",
        "#indices = np.random.permutation(len(img_paths))    # non-seeded random shuffle\n",
        "rs = np.random.RandomState(seed=rand_seed)\n",
        "indices = rs.permutation(len(img_paths))\n",
        "\n",
        "img_paths = [img_paths[i] for i in indices]\n",
        "mask_paths = [mask_paths[i] for i in indices]\n",
        "\n",
        "train_img_paths = img_paths[: -n_val]\n",
        "train_mask_paths = mask_paths[:-n_val]\n",
        "\n",
        "val_img_paths = img_paths[-n_val:]\n",
        "val_mask_paths = mask_paths[-n_val:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lbynwqRGM7HY"
      },
      "source": [
        "## Compute sample weights & mean/std for training data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mbXwMXHdMM17"
      },
      "outputs": [],
      "source": [
        "y_train_labels = models_util.load_y(train_mask_paths)\n",
        "\n",
        "n_fg = np.sum(y_train_labels == 1)\n",
        "n_bg = np.sum(y_train_labels == 0)\n",
        "fg_weight = float(n_fg + n_bg) / (2.0 * n_fg)\n",
        "bg_weight = float(n_fg + n_bg) / (2.0 * n_bg)\n",
        "sample_weights = {0: bg_weight, 1: fg_weight}\n",
        "sample_weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ijCjw_62MWZR"
      },
      "outputs": [],
      "source": [
        "# Get the mean and std of the training set images\n",
        "x_train_imgs = models_util.load_x(img_paths)\n",
        "im_mean = np.mean(x_train_imgs)\n",
        "im_std = np.std(x_train_imgs)\n",
        "\n",
        "im_mean, im_std"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "roB3CCLLNjN_"
      },
      "source": [
        "<a name=\"image-transformations-augmentation\"></a>\n",
        "### Image transformations and augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fAZ_UNB2JbRr"
      },
      "outputs": [],
      "source": [
        "# Helper functions\n",
        "\n",
        "def get_resizer(ds_shape):\n",
        "    def ds_im_mask(image, mask):\n",
        "        \"\"\"Downscale image with Lanczos interpolation and mask with nearest neighbor\"\"\"\n",
        "        image = cv2.resize(image, ds_shape, interpolation=cv2.INTER_LANCZOS4)\n",
        "        mask = np.array(Image.fromarray(mask).resize(ds_shape, resample=Image.Resampling.NEAREST))\n",
        "        return {'image': image, 'mask': mask}\n",
        "    return ds_im_mask\n",
        "\n",
        "def get_normalizer(mean, std):\n",
        "    def norm_im(image, mask):\n",
        "        \"\"\"Normalize image with mean and std of training set images\"\"\"\n",
        "        image = ((image - mean) / std).astype(np.float32)\n",
        "        return {'image': image, 'mask': mask}\n",
        "    return norm_im"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qqr7yKMlMWfg"
      },
      "outputs": [],
      "source": [
        "train_transforms = train_transforms = [\n",
        "    A.Compose([\n",
        "        A.Rotate(p=1.0, border_mode=cv2.BORDER_CONSTANT, value=0, mask_value=0),\n",
        "        A.RandomCrop(height=crop_window[0], width=crop_window[1]),\n",
        "        A.Flip(p=0.5),\n",
        "        A.RandomBrightnessContrast(p=0.7),\n",
        "        A.OneOf([\n",
        "                A.MultiplicativeNoise(p=0.5, elementwise=True),\n",
        "                A.AdvancedBlur(p=0.5)\n",
        "        ], p=0.8),\n",
        "    ]),     # Albumentations pipeline\n",
        "    get_elastic_dual_transform(p=0.85),\n",
        "    get_resizer(target_shape),\n",
        "    get_normalizer(im_mean, im_std)\n",
        "]\n",
        "\n",
        "val_transforms = [\n",
        "    A.Compose([\n",
        "        A.RandomCrop(height=crop_window[0], width=crop_window[1]),\n",
        "        A.Flip(p=0.5),\n",
        "        A.RandomRotate90(p=0.5)\n",
        "    ]),\n",
        "    get_resizer(target_shape),\n",
        "    get_normalizer(im_mean, im_std)\n",
        "]\n",
        "\n",
        "train_augmentor = get_batch_augmentor(train_transforms)\n",
        "val_augmentor = get_batch_augmentor(val_transforms)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_wrq6Uz-Nqqu"
      },
      "source": [
        "### Create the training and validation data generators"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4XL-75mJMWmG"
      },
      "outputs": [],
      "source": [
        "rs = np.random.RandomState(seed=rand_seed)\n",
        "\n",
        "train_gen = models_util.BinaryMaskSequence(\n",
        "    batch_size, train_img_paths, train_mask_paths, rs,\n",
        "    models_util.load_x, models_util.load_y, augmentation_function=train_augmentor,\n",
        "    sample_weights=sample_weights, repeat_n_times=repeat_dset_n_times, shuffle=True\n",
        ")\n",
        "\n",
        "val_gen = models_util.BinaryMaskSequence(\n",
        "    batch_size, val_img_paths, val_mask_paths,\n",
        "    rs, models_util.load_x, models_util.load_y, augmentation_function=val_augmentor,\n",
        "    sample_weights=sample_weights, repeat_n_times=repeat_dset_n_times, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zy2K2QARN5oa"
      },
      "source": [
        "### Test the training generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z2rJs7ETMWyL"
      },
      "outputs": [],
      "source": [
        "X, y, _ = train_gen[1]\n",
        "for i in range(batch_size):\n",
        "    fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
        "    ax[0].imshow(X[i][:,:,0], cmap='gray')\n",
        "    ax[1].imshow(y[i][:,:,0], cmap='gray')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-bKVfa1QN4P7"
      },
      "source": [
        "### Test the validation generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JPEpXSfSMW1U"
      },
      "outputs": [],
      "source": [
        "X, y, _ = val_gen[1]\n",
        "for i in range(batch_size):\n",
        "    fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
        "    ax[0].imshow(X[i][:,:,0], cmap='gray')\n",
        "    ax[1].imshow(y[i][:,:,0], cmap='gray')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GEQynUjIOBnR"
      },
      "source": [
        "<a name=\"training-configuration\"></a>\n",
        "## Training configuration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oiACYpC5OLTd"
      },
      "source": [
        "*We'll warm up to the initial learning rate and either use a cyclic schedule or reduce it when val_loss plateaus.*\n",
        "\n",
        "Parameters you should customize:\n",
        "- `n_epochs`\n",
        "- `hp_search_epochs`\n",
        "- `weight_decay`\n",
        "\n",
        "Extra parameters you should customize for cyclic schedule:\n",
        "- `cyclic_lr_mult`\n",
        "- `num_cycles`\n",
        "\n",
        "Extra parameters you should customize for reduce lr on plateau:\n",
        "- `lr_patience`\n",
        "- `lr_reduction_factor`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iS87He-FOR9y"
      },
      "outputs": [],
      "source": [
        "n_epochs = 50\n",
        "hp_search_epochs = n_epochs // 5\n",
        "\n",
        "epoch_len = math.ceil(((len(train_img_paths)) * train_gen.repeat_n_times) / batch_size)\n",
        "linear_warmup_steps = epoch_len\n",
        "\n",
        "# use_cosine_decay_restarts: true to use a cyclic lr schedule, false for ReduceLROnPlateau\n",
        "use_cosine_decay_restarts = True\n",
        "\n",
        "# get optimizer options for grid search (vary the initial learning rate)\n",
        "hp_search_optimizer_options = []\n",
        "for initial_lr in hp_search_initial_lr_options:\n",
        "    if use_cosine_decay_restarts:\n",
        "        # cosine annealing parameters - timed so the last cycle ends at the end of training\n",
        "        cycle_lr_mult = 0.5         # decrease initial lr at the end of each cycle (m_mul)\n",
        "        num_cycles = 3              # number of full cycles\n",
        "\n",
        "        # figure out what the first_decay_steps should be\n",
        "        # start counting after the warmup steps\n",
        "        total_steps = epoch_len * n_epochs - linear_warmup_steps\n",
        "\n",
        "        # round up and add 1 to prevent an extra restart at the end\n",
        "        first_decay_steps = math.ceil(total_steps / (2**num_cycles - 1)) + 1\n",
        "\n",
        "        learning_rate = optimizers.schedules.CosineDecayRestarts(\n",
        "            initial_learning_rate=initial_lr,\n",
        "            first_decay_steps=first_decay_steps,\n",
        "            t_mul=2.0,  # our first_decay_steps calculation assumes t_mul=2\n",
        "            m_mul=cycle_lr_mult\n",
        "        )\n",
        "        learning_rate = optimizers.serialize(learning_rate)\n",
        "    else:\n",
        "        # patience: number of epochs with no improvement after which learning rate will be reduced\n",
        "        patience = 4\n",
        "        lr_reduction_factor = 0.5\n",
        "        learning_rate = initial_lr\n",
        "        reduce_lr = ReduceLROnPlateau(\n",
        "            monitor='val_loss',\n",
        "            factor=lr_reduction_factor,\n",
        "            patience=patience,\n",
        "            verbose=1,\n",
        "            mode='min'\n",
        "        )\n",
        "\n",
        "    lr_schedule = models_util.WarmupSchedule(warmup_steps=linear_warmup_steps,\n",
        "                                             after_warmup_lr=learning_rate)\n",
        "\n",
        "    weight_decay = 1e-4     # weight decay for AdamW\n",
        "\n",
        "    optimizer = optimizers.experimental.AdamW(learning_rate=lr_schedule, weight_decay=weight_decay)\n",
        "    optimizer_config = optimizers.serialize(optimizer)\n",
        "\n",
        "    hp_search_optimizer_options.append(optimizer_config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_BmoZNLSN-dx"
      },
      "source": [
        "## Hyperparameter search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6caAw27VMW4V"
      },
      "outputs": [],
      "source": [
        "metrics=[models_util.mean_iou_coef_factory(thresh=0.5)]\n",
        "loss = BinaryCrossentropy()\n",
        "\n",
        "callbacks = []\n",
        "\n",
        "# csv logger - clear previous log if it exists\n",
        "\n",
        "if os.path.exists(f\"{training_dir}/hp_search_log.csv\"):\n",
        "    os.remove(f\"{training_dir}/hp_search_log.csv\")\n",
        "csv_logger = CSVLogger(f\"{training_dir}/hp_search_log.csv\", append=True)\n",
        "\n",
        "callbacks.append(csv_logger)\n",
        "\n",
        "# reduce lr on plateau\n",
        "if not use_cosine_decay_restarts:\n",
        "    callbacks.append(reduce_lr)\n",
        "\n",
        "gs = models.UNetXceptionGridSearch(\n",
        "    save_dir=f\"{training_dir}/hp_search\",\n",
        "    filter_counts_options=filter_counts_options,\n",
        "    n_outputs=1,\n",
        "    img_shape=target_shape,\n",
        "    optimizer_cfg_options=hp_search_optimizer_options,\n",
        "    loss=loss,\n",
        "    output_act=\"sigmoid\",\n",
        "    metrics=metrics,\n",
        "    callbacks=callbacks\n",
        ")\n",
        "\n",
        "with custom_object_scope({'WarmupSchedule': models_util.WarmupSchedule}):\n",
        "    gs.search(\n",
        "        \"val_mean_iou_coef\",\n",
        "        \"max\",\n",
        "        train_gen,\n",
        "        steps_per_epoch=len(train_gen),\n",
        "        search_verbose=True,\n",
        "        validation_data=val_gen,\n",
        "        validation_steps=len(val_gen),\n",
        "        epochs=hp_search_epochs,\n",
        "        use_multiprocessing=True, workers=4\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mvu_ZeaLzrjF"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Ds7w9j7KXVV"
      },
      "outputs": [],
      "source": [
        "# Get the best learning rate schedule\n",
        "with custom_object_scope({'WarmupSchedule': models_util.WarmupSchedule}):\n",
        "    best_lr_schedule = gs.best_optimizer_cfg['config']['learning_rate']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fbXoqc6nHxXK"
      },
      "outputs": [],
      "source": [
        "# Show the best hyperparameters\n",
        "print(\"Best filter counts: \", gs.best_filter_counts)\n",
        "print(\"Best optimizer: \", gs.best_optimizer_cfg)\n",
        "print(\"Best initial learning rate: \", round(float(best_lr_schedule(linear_warmup_steps)), 6))\n",
        "print(\"Best score: \", gs.best_score)\n",
        "print(\"Best score index: \", gs.best_score_idx)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x0-TKb7JO_fd"
      },
      "source": [
        "## Train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8rxVRJp8MqCC"
      },
      "outputs": [],
      "source": [
        "K.clear_session()\n",
        "\n",
        "with custom_object_scope({'WarmupSchedule': models_util.WarmupSchedule}):\n",
        "    optimizer = optimizers.deserialize(gs.best_optimizer_cfg)\n",
        "\n",
        "model = models.build_UNetXception(1, target_shape, filter_counts=gs.best_filter_counts,\n",
        "                                  output_act=\"sigmoid\")\n",
        "\n",
        "metrics=[models_util.mean_iou_coef_factory(thresh=0.5)]\n",
        "\n",
        "model.compile(optimizer=optimizer, loss=BinaryCrossentropy(), metrics=metrics)\n",
        "\n",
        "callbacks = [\n",
        "    ModelCheckpoint(checkpoint_save_path, save_best_only=True, save_weights_only=True),\n",
        "    TensorBoard(log_dir=log_dir, histogram_freq=1),\n",
        "    CSVLogger(f\"{log_dir}/training_log.csv\")\n",
        "]\n",
        "\n",
        "callbacks = callbacks if use_cosine_decay_restarts else callbacks + [reduce_lr]\n",
        "\n",
        "h = model.fit(train_gen, validation_data=val_gen, epochs=n_epochs, callbacks=callbacks)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SoaoOXF3PHMs"
      },
      "source": [
        "## Test the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vfzgfC3hPIvK"
      },
      "outputs": [],
      "source": [
        "val_batch_num = 0\n",
        "val_x, val_y, _ = val_gen[val_batch_num]\n",
        "preds = model.predict(val_x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3xt-aPW5PM9X"
      },
      "outputs": [],
      "source": [
        "for sample_idx in range(0, batch_size):\n",
        "    image = val_x[sample_idx]\n",
        "    ground_truth = val_y[sample_idx]\n",
        "    prediction = preds[sample_idx]\n",
        "    fig, ax = plt.subplots(1, 4, figsize=(20, 5))\n",
        "    ax[0].imshow(image[:,:,0], cmap='gray')\n",
        "    ax[0].set_title(\"Image\")\n",
        "    ax[1].imshow(ground_truth[:,:,0], cmap='gray')\n",
        "    ax[1].set_title(\"True Segmentation\")\n",
        "    ax[2].imshow(prediction[:,:,0], cmap='gray')\n",
        "    ax[2].set_title(\"Prediction\")\n",
        "    ax[3].imshow(np.greater(prediction, 0.5)[:,:,0], cmap='gray')\n",
        "    ax[3].set_title(\"Predicted Segmentation\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jpX4db2rL71k"
      },
      "source": [
        "## Save configuration for patch-blending segmentor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4k7goqalL4RS"
      },
      "outputs": [],
      "source": [
        "# Create patch segmentor config and save it\n",
        "cfg = {\n",
        "    \"patch_size\": crop_window[0],\n",
        "    \"checkpoint_file\": checkpoint_save_path.name,\n",
        "    \"filter_counts\": gs.best_filter_counts,\n",
        "    \"ds_ratio\": target_shape[0] / crop_window[0],\n",
        "    \"norm_mean\": im_mean,\n",
        "    \"norm_std\": im_std,\n",
        "    \"channels\": 1\n",
        "}\n",
        "models_util.save_unet_patch_segmentor_cfg(cfg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e-95-095zrjG"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

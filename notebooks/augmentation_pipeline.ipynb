{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from skimage.morphology import skeletonize\n",
    "import cv2\n",
    "import numpy as np\n",
    "from skimage import measure, morphology\n",
    "import random\n",
    "from pathlib import Path\n",
    "import albumentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change mask_paths to match paths for the original datasets\n",
    "mask_paths = glob('set_*/train/masks/*.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_paths = [fp for fp in mask_paths if not fp.endswith('_processed.png')]\n",
    "random.shuffle(mask_paths)\n",
    "skeleton_split_idx = int(len(mask_paths) // 2)\n",
    "masks_to_skeletonize = mask_paths[:skeleton_split_idx]\n",
    "im_names = [Path(fp).name for fp in mask_paths]\n",
    "train_set_split_idx = int(len(im_names) // (4/3))\n",
    "test_set_split_idx = int(len(im_names) // 14)\n",
    "train_set = im_names[:train_set_split_idx]\n",
    "val_set = im_names[train_set_split_idx:-test_set_split_idx]\n",
    "test_set = im_names[-test_set_split_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_small_islands(mask):\n",
    "    inverse_mask = 1 - mask\n",
    "    labeled_regions_inverse = measure.label(inverse_mask, connectivity=1)\n",
    "    labeled_inverse_regions = morphology.remove_small_objects(labeled_regions_inverse, min_size=5)\n",
    "    mask[labeled_inverse_regions == 0] = 1\n",
    "    labeled_regions = measure.label(mask, connectivity=1)\n",
    "    labeled_regions = morphology.remove_small_objects(labeled_regions, min_size=50)\n",
    "    mask[labeled_regions == 0] = 0\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dset_paths = ['all_skeleton', 'mix_skeleton', 'no_skeleton']\n",
    "for new_dset_path in new_dset_paths:\n",
    "    for split in ['train', 'val', 'test']:\n",
    "        for category in ['img', 'mask']:\n",
    "            new_path = Path(new_dset_path) / split / category\n",
    "            new_path.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'new_dset_paths' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mfor\u001b[39;00m new_dset_path \u001b[39min\u001b[39;00m new_dset_paths:\n\u001b[0;32m      2\u001b[0m \t\u001b[39mfor\u001b[39;00m mask_path \u001b[39min\u001b[39;00m mask_paths:    \n\u001b[0;32m      3\u001b[0m \t\tmask \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mimread(mask_path, \u001b[39m0\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'new_dset_paths' is not defined"
     ]
    }
   ],
   "source": [
    "for new_dset_path in new_dset_paths:\n",
    "\tfor i in range(0, len(mask_paths)):\n",
    "\t\tmask_path = mask_paths[i]\n",
    "\t\tmask = cv2.imread(mask_path, 0)\n",
    "\t\timg_path = mask_path.replace('masks', 'images')\n",
    "\t\timg = cv2.imread(img_path, cv2.IMREAD_ANYDEPTH)\n",
    "\t\tkernel = np.ones((2, 2), np.uint8)\n",
    "\t\tmask = cv2.dilate(mask, kernel, iterations=1)\n",
    "\t\tmask[mask==255] = 1\n",
    "\t\tmask = remove_small_islands(mask)\n",
    "\t\tif (\n",
    "            (mask_path in masks_to_skeletonize and new_dset_path=='mix_skeleton')\n",
    "            or (mask_path == 'all_skeleton')\n",
    "\t\t):\n",
    "\t\t\tmask = skeletonize(mask, method='lee')\n",
    "\t\t\tkernel = np.ones((3, 3), np.uint8)\n",
    "\t\t\tmask = cv2.dilate(mask, kernel, iterations=1)\n",
    "\t\tmask[mask==1] = 255\n",
    "\t\tim_name = Path(mask_path).name\n",
    "\t\tif im_name in train_set:\n",
    "\t\t\ttrain_val_test = 'train'\n",
    "\t\telif im_name in val_set:\n",
    "\t\t\ttrain_val_test = 'val'\n",
    "\t\telif im_name in test_set:\n",
    "\t\t\ttrain_val_test = 'test'\n",
    "\t\telse:\n",
    "\t\t\traise ValueError\n",
    "\t\tmask_save_path = f'{new_dset_path}/{train_val_test}/mask_{i}'\n",
    "\t\timg_save_path = f'{new_dset_path}/{train_val_test}/img{i}'\n",
    "        # Downscale mask and image to 1024x1024\n",
    "\t\tdim = (1024, 1024)\n",
    "\t\tmask = cv2.resize(mask, dim, cv2.INTER_AREA)\n",
    "\t\timg = cv2.resize(img, dim, cv2.INTER_AREA)\n",
    "\t\tcv2.imwrite(mask_save_path, mask)\n",
    "\t\tcv2.imwrite(img_save_path, img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augmentations\n",
    "'''\n",
    "https://albumentations.ai/docs/getting_started/image_augmentation/\n",
    "Expand dataset ~1000x (to 28k image/mask pairs in total for train+val+test sets)\n",
    "Compose:\n",
    "- piecewise affine (p=0.9)\n",
    "- one of (probability=0.8): (not on mask)\n",
    "    - randomgamma (probability=0.25)\n",
    "    - randombrightnesscontrast (probability=0.25)\n",
    "    - randomtonecurve (probability=0.25)\n",
    "    - clahe (probability=0.25)\n",
    "- one of (probability=0.75):\n",
    "    - verticalflip (probability=0.5)\n",
    "    - randomrotate90 (probability=0.5)\n",
    "'''\n",
    "\n",
    "transform = albumentations.Compose([\n",
    "\talbumentations.PiecewiseAffine(p=0.9), \n",
    "\talbumentations.OneOf([albumentations.RandomGamma(p=0.25), albumentations.RandomBrightnessContrast(p=0.25), albumentations.RandomToneCurve(p=0.25), albumentations.CLAHE(p=0.25)], 0.8),\n",
    "\talbumentations.OneOf([albumentations.VerticalFlip(p=0.5), albumentations.RandomRotate90(p=0.5)], 0.75)\n",
    "])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e920456a2527b588c7ebe0d1d208ed51e70422f332c83a3f8a3395b6b353438c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

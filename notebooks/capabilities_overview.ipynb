{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e567dfec-b590-4413-9cbd-cec17bc9e28e",
   "metadata": {},
   "source": [
    "# Analysis Capabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec0959e-b909-4f71-9ea3-d21029ad47cf",
   "metadata": {},
   "source": [
    "## 1. Cell Area"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deef5ee6-89d3-48c4-afa7-7b89b5833ee3",
   "metadata": {},
   "source": [
    "The cell area estimation is performed using a procedure that incorporates a Gaussian Mixture Model. Two Gaussian curves are fit to the pixel intensities of an image. One curve fits the \"background\" pixels and one curve fits the \"foreground\" pixels. Cell area is computed by thresholding based on\n",
    "\n",
    "$$ \\mu_{\\text{foreground}} + \\gamma \\times \\sigma_{\\text{foreground}} , $$\n",
    "\n",
    "where $\\gamma$ is some multiplier of the foreground standard deviation.\n",
    "\n",
    "1. $\\gamma = 0$: Pixels with intensities greater than $ \\mu_{\\text{foreground}} $ will pass the threshold\n",
    "2. $\\gamma > 0$: More strict than (1). Smaller $ \\gamma \\Longrightarrow $ fewer pixels pass the threshold\n",
    "3. $\\gamma < 0$: Less strict than (1). Larger $ \\gamma \\Longrightarrow $ more pixels pass the threshold\n",
    "\n",
    "**Notes**: The cell area script assumes that the brightest regions of your images are the cells. If this isn't the case, consider including a preprocessing step to make them this way."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c746004b-6b3a-4021-a380-2ecbdb4c31fb",
   "metadata": {},
   "source": [
    "## 2. Z Projection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba8ddfa-ce6b-420d-8be3-06231b5953e8",
   "metadata": {},
   "source": [
    "The Z projection of input Z stacks can be computed using several methods:\n",
    "\n",
    "* Minimum pixel intensity\n",
    "* Maximum pixel intensity\n",
    "* Median pixel intensity\n",
    "* Average pixel intensity\n",
    "* Focus stacking (pixel-wise Laplacian)\n",
    "\n",
    "A Z stack is a 3D collection of grayscale images. The Z projection is the 2D image that results when images are collapsed along the $z$-axis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b5e0bf-73ee-458a-a240-26f1a66e813b",
   "metadata": {},
   "source": [
    "### Minimum pixel intensity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cbfeaf3-0eef-4152-ba02-c1084bcf9f16",
   "metadata": {},
   "source": [
    "Set pixel $ (x, y) $ to $ (x, y, z_{\\text{min}}) $, the minimum pixel intensity along the $z$-axis at location $ (x, y) $."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b7a93b-0f32-4fa0-8945-30c8ccf1ebb9",
   "metadata": {},
   "source": [
    "### Maximum pixel intensity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2710669-4058-4b37-9297-dac253e2ac3a",
   "metadata": {},
   "source": [
    "Set pixel $ (x, y) $ to $ (x, y, z_{\\text{max}}) $, the maximum pixel intensity along the $z$-axis at location $ (x, y) $."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26594f36-4f7a-4d53-bc30-8de45ef54198",
   "metadata": {},
   "source": [
    "### Median pixel intensity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58be43c-c999-4422-bb36-81e3ec964987",
   "metadata": {},
   "source": [
    "Set pixel $ (x, y) $ to $ (x, y, z_{\\text{med}}) $, the median pixel intensity along the $z$-axis at location $ (x, y) $."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d1853b-7a77-43dc-a7d4-dc7f791ce1e1",
   "metadata": {},
   "source": [
    "### Average pixel intensity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb8301a-3610-4b3d-ba1e-48c37c42df5b",
   "metadata": {},
   "source": [
    "Set pixel $ (x, y) $ to $ (x, y, z_{\\text{avg}}) $, the average pixel intensity along the $z$-axis at location $ (x, y) $."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba1deb5-4d06-473c-9787-6c2b27bac468",
   "metadata": {},
   "source": [
    "### Focus stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece800ef-f762-4be6-84ab-47badace6925",
   "metadata": {},
   "source": [
    "Set pixel $ (x, y) $ to $ (x, y, z_{\\text{max foc}}) $, the value of the most \"in-focus\" pixel along the $z$-axis at location $ (x, y) $."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc1a58b3-7eef-4b2e-93b8-d75d8cdfa3f8",
   "metadata": {},
   "source": [
    "## 3. Invasion Depth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252a64b8-a20f-4de6-a71f-9a3a917a1b2c",
   "metadata": {},
   "source": [
    "The invasion depth (within a given Z stack) is performed using a binary classifier deep neural network (based on the ResNet50 architecture).\n",
    "\n",
    "Given a Z stack of $ k $ slices (Z positions), the underlying classifier determines if each image has a sufficient amount of in-focus cell area to be considered to demonstrate \"invasion\".\n",
    "\n",
    "In symbols, a Z stack (here shown in *descending* order)\n",
    "\n",
    "$$ \\mathbf{Z} = (z_k, z_{k-1}, ..., z_0),$$\n",
    "\n",
    "is fed into the invasion depth analysis system, which outputs two results:\n",
    "\n",
    "1. A collection of \"probabilities\", $ \\hat{\\mathbf{p}} $, showing the model's confidence that invasion has been identified,\n",
    "$$ \\hat{\\mathbf{p}} = (p_k, p_{k-1}, ..., p_0),$$\n",
    "2. A collection of classifications, $ \\hat{y}_{p} $ thresholded at a given value (typically $p_i > 0.5$,\n",
    "$$ \\hat{\\mathbf{y}} = (\\hat{y}_{k}, \\hat{y}_{k-1}, ..., \\hat{y}_0) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58718ffc",
   "metadata": {},
   "source": [
    "## 4. Microvessel formation\n",
    "\n",
    "Microvessel formation is analyzed using a two-step process: semantic binary segmentation and topological data analysis.\n",
    "\n",
    "### Semantic Binary Segmentation\n",
    "A trained U-Net Xception-style model segments microvessels from the image background. The model outputs a probabilistic segmentation, indicating the likelihood of each pixel being part of a vessel.\n",
    "\n",
    "Training of the model involves:\n",
    "\n",
    "1. Data Preparation: Dataset of fifty high-resolution, manually annotated images, split into training, validation, and test sets.\n",
    "2. Data Augmentation: Application of transformations such as rotation, cropping, flipping, brightness and contrast alteration, noise addition, gaussian blur, and elastic deformations.\n",
    "3. Model Training: Conducted with a grid search to determine optimal hyperparameters. The model is trained for fifty epochs.\n",
    "\n",
    "Inference on a whole image involves two steps:\n",
    "1. Segment individual, overlapping tiles on the image, with a similar crop size used during training.\n",
    "2. Uses code from [Smoothly-Blend-Image-Patches](https://github.com/Vooban/Smoothly-Blend-Image-Patches) to blend the overlapping tiles together, producing a realistic, smooth segmentation of the whole image.\n",
    "\n",
    "### Topological Data Analysis\n",
    "After segmentation, the microvessel network is analyzed using the Disperse algorithm to extract a graph representation, referred to as the Morse skeleton. This step involves:\n",
    "\n",
    "1. Preprocessing: Images are preprocessed to remove background noise and isolate the microvessel network.\n",
    "2. Graph Extraction: The Disperse algorithm extracts a graph representation from the segmented images.\n",
    "3. Network Simplification: Includes removing branches shorter than a threshold and smoothing branch trajectories. At this point, we can extract a color-coded visualization of the network.\n",
    "4. Persistence Homology: Utilizes persistent homology to characterize the branching structure of the microvessels, resulting in a persistence barcode. The basic metrics we extract are the average branch length and number of branches."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d28603f",
   "metadata": {},
   "source": [
    "**Notes**:\n",
    "- Like the cell area script, the microvessel analysis script assumes that the brightest regions of your images are the cells. If this isn't the case, consider including a preprocessing step to make them this way.\n",
    "- The script requires a trained model. See notebooks/microvessels_segmentation_training. Recommended: Try using the pretrained model first. If the pretrained model does not work well, use an interactive segmentation tool to annotate 50 or so of your images and train a new model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7aaf7d",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

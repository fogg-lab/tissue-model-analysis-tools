{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c12c68d-93a1-41af-b05c-e56b17582e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.backend as K\n",
    "import numpy as np\n",
    "import dask as d\n",
    "import os\n",
    "import cv2\n",
    "import multiprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from glob import glob\n",
    "from copy import deepcopy\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.metrics import BinaryAccuracy\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.applications import resnet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a402a73f-b4a9-44ba-8ae5-06641c0668f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_cores = multiprocessing.cpu_count()\n",
    "n_cores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fdc59e17-d035-4e8d-ad5f-ca7adfa21f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fl_tissue_model_tools import data_prep, dev_config, models, defs\n",
    "import fl_tissue_model_tools.preprocessing as prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c960e34-fb3c-463b-8bc5-952730a064dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs = dev_config.get_dev_directories(\"../dev_paths.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77f26842-80d0-4710-ab9f-3f19c1029199",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_data_path = f\"{dirs.data_dir}/invasion_data/development\"\n",
    "seed = 2049\n",
    "resnet_inp_shape = (128, 128, 3)\n",
    "# Binary classification -> only need 1 output unit\n",
    "n_outputs = 1\n",
    "val_split = 0.2\n",
    "batch_size = 32\n",
    "frozen_epochs = 20\n",
    "fine_tune_epochs = 20\n",
    "fine_tune_lr = 1e-5\n",
    "class_labels = {\"no_invasion\": 0, \"invasion\": 1}\n",
    "\n",
    "# Early stopping\n",
    "es_criterion = \"val_loss\"\n",
    "es_mode = \"min\"\n",
    "# Update these depending on seriousness of experiment\n",
    "es_patience = 10\n",
    "es_min_delta = 0.0001\n",
    "\n",
    "# Model saving\n",
    "cp_criterion = \"val_loss\"\n",
    "cp_mode = \"min\"\n",
    "cp_frozen_filepath = \"../model_training/resnet50_invasion_depth_demo_v1_best_frozen_weights.h5\"\n",
    "cp_fine_tune_filepath = \"../model_training/resnet50_invasion_depth_demo_v1_best_fine_tune_weights.h5\"\n",
    "cp_best_only = True\n",
    "# Need to set to True otherwise base model \"layer\" won't save/load properly\n",
    "cp_weights_only = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a2e6e22-ffed-459e-8895-f1917396c661",
   "metadata": {},
   "source": [
    "# Prep for loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d22b149-c675-4b1c-95e7-909716249d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "rs = np.random.RandomState(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6a69dfe-afa0-41fa-8f26-c8463105bf3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_paths = {v: glob(f\"{root_data_path}/train/{k}/*.tif\") for k, v in class_labels.items()}\n",
    "for k, v in data_paths.items():\n",
    "    rs.shuffle(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "940352be-2f0d-4e8a-845b-8873c3629a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_counts = {k: len(v) for k, v in data_paths.items()}\n",
    "val_counts = {k: round(v * val_split) for k, v in data_counts.items()}\n",
    "train_counts = {k: v - val_counts[k] for k, v in data_counts.items()}\n",
    "train_class_weights = prep.balanced_class_weights_from_counts(train_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c9bdee1-cf3a-4713-800e-750180b6aa06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 403, 1: 47}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e48279d3-14b3-43a7-80c4-fd99ddf41749",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.5590062111801242, 1: 4.7368421052631575}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a3b38c5-6c48-4858-aec1-de470844072a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data_paths = {k: v[val_counts[k]:] for k, v in data_paths.items()}\n",
    "val_data_paths = {k: v[:val_counts[k]] for k, v in data_paths.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4105535b-e87d-4efb-9045-6cc547f17a23",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6aff4bfe-ba64-4a4f-a316-6a7607cc9b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InvasionDataGenerator(Sequence):\n",
    "    def __init__(self, data_paths, class_labels, batch_size, img_shape, random_state, class_weights=None, shuffle=True, augmentation_function=None):\n",
    "        self.data_paths = deepcopy(data_paths)\n",
    "        self.batch_size = batch_size\n",
    "        self.img_shape = img_shape\n",
    "        self.class_labels = deepcopy(class_labels)\n",
    "        self.class_paths = {}\n",
    "        self.class_counts = {}\n",
    "        self.img_paths = []\n",
    "        self.img_labels = []\n",
    "        self.shuffle = shuffle\n",
    "        self.rs = random_state\n",
    "        self.augmentation_function = augmentation_function\n",
    "        self._get_paths_and_counts(data_paths)\n",
    "        self.indices = np.arange(len(self.img_paths), dtype=np.uint)\n",
    "        if class_weights != None:\n",
    "            self.class_weights = deepcopy(class_weights)\n",
    "        else:\n",
    "            self.class_weights = None\n",
    "        self.shuffle_indices()\n",
    "\n",
    "    def __len__(self):\n",
    "        # return len()\n",
    "        return len(self.img_paths) // self.batch_size\n",
    "\n",
    "    def __getitem__(self, index):        \n",
    "        batch_idx_start = index * self.batch_size\n",
    "        batch_idx_end = batch_idx_start + batch_size\n",
    "        batch_indices = self.indices[batch_idx_start: batch_idx_end]\n",
    "\n",
    "        img_paths = [self.img_paths[i] for i in batch_indices]\n",
    "        # Should it be (B,) or (B,1)?\n",
    "        y = np.array([self.img_labels[i] for i in batch_indices])\n",
    "\n",
    "        # Generate data\n",
    "        X = self.prep_images(img_paths)\n",
    "        \n",
    "        if self.augmentation_function != None:\n",
    "            X = self.augmentation_function(X, self.rs, expand_dims=False)\n",
    "        \n",
    "        if self.class_weights != None:\n",
    "            # Weight classes by relative proportions in the training set\n",
    "            w = np.array([self.class_weights[y_] for y_ in y])\n",
    "            return X, y, w\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    \n",
    "    def _get_paths_and_counts(self, data_paths):\n",
    "        self.class_paths = deepcopy(data_paths)\n",
    "        self.class_counts = {c: len(pn) for c, pn in self.class_paths.items()}\n",
    "        for k, v in self.class_paths.items():\n",
    "            # Paths to each image\n",
    "            self.img_paths.extend(v)\n",
    "            # Associate labels with each image path\n",
    "            self.img_labels.extend(list(np.repeat(k, len(v))))\n",
    "            \n",
    "    def _load_img(self, path):\n",
    "        img = cv2.imread(path, cv2.IMREAD_ANYDEPTH)\n",
    "        img = prep.min_max_(cv2.resize(img, self.img_shape, cv2.INTER_LANCZOS4).astype(np.float32), defs.GS_MIN, defs.GS_MAX, defs.TIF_MIN, defs.TIF_MAX)\n",
    "        img = np.repeat(img[:, :, np.newaxis], 3, axis=2)\n",
    "        return img\n",
    "            \n",
    "    def shuffle_indices(self):\n",
    "        # print(\"shuffling\")\n",
    "        self.rs.shuffle(self.indices)\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        self.indices = np.arange(len(self.img_paths), dtype=np.uint)\n",
    "        if self.shuffle == True:\n",
    "            self.shuffle_indices()\n",
    "\n",
    "    def prep_images(self, paths):\n",
    "        imgs = np.array(d.compute((d.delayed(self._load_img)(p) for p in paths))[0])\n",
    "        return resnet50.preprocess_input(imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5d89ed15-f0c8-4469-946c-f0c0e6cbb628",
   "metadata": {},
   "outputs": [],
   "source": [
    "# With class weights\n",
    "train_datagen = InvasionDataGenerator(train_data_paths, class_labels, batch_size, resnet_inp_shape[:2], rs, class_weights=train_class_weights, augmentation_function=prep.augment_imgs)\n",
    "val_datagen = InvasionDataGenerator(val_data_paths, class_labels, batch_size, resnet_inp_shape[:2], rs, class_weights=train_class_weights, augmentation_function=prep.augment_imgs)\n",
    "# # Without class weights\n",
    "# train_datagen = InvasionDataGenerator(train_data_paths, class_labels, batch_size, resnet_inp_shape[:2], rs, augmentation_function=prep.augment_imgs)\n",
    "# val_datagen = InvasionDataGenerator(val_data_paths, class_labels, batch_size, resnet_inp_shape[:2], rs, augmentation_function=prep.augment_imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f50e81cb-bfd6-4ac8-a36d-da6ca500c5f3",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5f59ef1d-0f95-4a14-a92d-327229a104a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b5bbe2fe-8e5b-4e69-a87d-81dcee513b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "tl_model = models.build_ResNet50_TL(\n",
    "    n_outputs,\n",
    "    resnet_inp_shape,\n",
    "    base_last_layer=\"conv5_block3_out\",\n",
    "    # base_last_layer=\"conv5_block2_out\",\n",
    "    # base_last_layer=\"conv5_block1_out\",\n",
    "    # base_last_layer=\"conv4_block6_out\",\n",
    "    # base_last_layer=\"conv4_block3_out\",\n",
    "    # base_last_layer=\"conv4_block1_out\",\n",
    "    # base_last_layer=\"conv3_block4_out\",\n",
    "    # Switch to softmax once n_outputs > 1\n",
    "    output_act=\"sigmoid\",\n",
    "    base_model_trainable=False\n",
    ")\n",
    "tl_model.compile(optimizer=Adam(), loss=BinaryCrossentropy(), metrics=[BinaryAccuracy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "134be685-feda-4ef2-b1f3-e431dcf88233",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 128, 128, 3)]     0         \n",
      "_________________________________________________________________\n",
      "base_model (Functional)      (None, 4, 4, 2048)        23587712  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 2049      \n",
      "=================================================================\n",
      "Total params: 23,589,761\n",
      "Trainable params: 2,049\n",
      "Non-trainable params: 23,587,712\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tl_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4a30cd0a-6cef-4e3b-b85a-b95be2cd08b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "es_callback = EarlyStopping(monitor=es_criterion, mode=es_mode, min_delta=es_min_delta, patience=es_patience)\n",
    "cp_callback = ModelCheckpoint(cp_frozen_filepath, monitor=cp_criterion, mode=cp_mode, save_best_only=cp_best_only, save_weights_only=cp_weights_only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c38e7b3e-8344-49f4-8c52-70d9ae017acd",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "11/11 [==============================] - 12s 343ms/step - loss: 0.5711 - binary_accuracy: 0.7188 - val_loss: 0.6884 - val_binary_accuracy: 0.8594\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 4s 213ms/step - loss: 0.4727 - binary_accuracy: 0.7670 - val_loss: 0.5470 - val_binary_accuracy: 0.7344\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 4s 236ms/step - loss: 0.4298 - binary_accuracy: 0.8210 - val_loss: 0.5369 - val_binary_accuracy: 0.6562\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 4s 225ms/step - loss: 0.4140 - binary_accuracy: 0.7642 - val_loss: 0.4669 - val_binary_accuracy: 0.7031\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 4s 245ms/step - loss: 0.3811 - binary_accuracy: 0.8040 - val_loss: 0.5105 - val_binary_accuracy: 0.8594\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 4s 237ms/step - loss: 0.3708 - binary_accuracy: 0.8182 - val_loss: 0.5367 - val_binary_accuracy: 0.7188\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 4s 225ms/step - loss: 0.3531 - binary_accuracy: 0.8295 - val_loss: 0.4750 - val_binary_accuracy: 0.8125\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 4s 224ms/step - loss: 0.3404 - binary_accuracy: 0.8608 - val_loss: 0.4276 - val_binary_accuracy: 0.7031\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 4s 230ms/step - loss: 0.3443 - binary_accuracy: 0.7955 - val_loss: 0.4125 - val_binary_accuracy: 0.7500\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 4s 224ms/step - loss: 0.3359 - binary_accuracy: 0.8636 - val_loss: 0.4660 - val_binary_accuracy: 0.8750\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 4s 238ms/step - loss: 0.3096 - binary_accuracy: 0.8324 - val_loss: 0.4446 - val_binary_accuracy: 0.8906\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 4s 221ms/step - loss: 0.3193 - binary_accuracy: 0.8778 - val_loss: 0.3744 - val_binary_accuracy: 0.7969\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 4s 224ms/step - loss: 0.2893 - binary_accuracy: 0.8210 - val_loss: 0.3346 - val_binary_accuracy: 0.8906\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 4s 229ms/step - loss: 0.3110 - binary_accuracy: 0.8580 - val_loss: 0.4229 - val_binary_accuracy: 0.8594\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 4s 224ms/step - loss: 0.2929 - binary_accuracy: 0.8750 - val_loss: 0.4363 - val_binary_accuracy: 0.7656\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 4s 229ms/step - loss: 0.2803 - binary_accuracy: 0.8750 - val_loss: 0.5805 - val_binary_accuracy: 0.8594\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 4s 239ms/step - loss: 0.2954 - binary_accuracy: 0.8551 - val_loss: 0.3656 - val_binary_accuracy: 0.8438\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 4s 225ms/step - loss: 0.2816 - binary_accuracy: 0.8636 - val_loss: 0.6190 - val_binary_accuracy: 0.8281\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 4s 223ms/step - loss: 0.2801 - binary_accuracy: 0.8722 - val_loss: 0.3883 - val_binary_accuracy: 0.7656\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 4s 219ms/step - loss: 0.2625 - binary_accuracy: 0.8807 - val_loss: 0.4709 - val_binary_accuracy: 0.7812\n"
     ]
    }
   ],
   "source": [
    "h1 = tl_model.fit(\n",
    "    train_datagen,\n",
    "    validation_data=val_datagen,\n",
    "    epochs=frozen_epochs,\n",
    "    callbacks=[es_callback, cp_callback],\n",
    "    workers=n_cores\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d21a2e1-6fb0-4252-97b6-7f395a21aa98",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Load best frozen weights before fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f727e052-d9c1-4613-8582-d93c31e46047",
   "metadata": {},
   "outputs": [],
   "source": [
    "tl_model.load_weights(cp_frozen_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e04b9f7-0220-47e1-88a1-b375166403e7",
   "metadata": {},
   "source": [
    "# Train model (all layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "826188ac-9b5f-4e90-8d9f-2fcaeaa1a98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make base model trainable (leave layers in inference mode)\n",
    "models.toggle_TL_freeze(tl_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9fce61bd-18b7-43e0-96f9-a309c763888f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tl_model.compile(optimizer=Adam(learning_rate=fine_tune_lr), loss=BinaryCrossentropy(), metrics=[BinaryAccuracy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ff63ccae-1830-4cda-ad44-a8bc1436562c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 128, 128, 3)]     0         \n",
      "_________________________________________________________________\n",
      "base_model (Functional)      (None, 4, 4, 2048)        23587712  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 2049      \n",
      "=================================================================\n",
      "Total params: 23,589,761\n",
      "Trainable params: 23,536,641\n",
      "Non-trainable params: 53,120\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tl_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4bc0da73-0193-4e18-bc4c-f84d86e17a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "es_callback = EarlyStopping(monitor=es_criterion, mode=es_mode, min_delta=es_min_delta, patience=es_patience)\n",
    "cp_callback = ModelCheckpoint(cp_fine_tune_filepath, monitor=cp_criterion, mode=cp_mode, save_best_only=cp_best_only, save_weights_only=cp_weights_only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "05c2c008-c5fe-473f-a209-9da1e56b64b4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "11/11 [==============================] - 11s 299ms/step - loss: 0.3902 - binary_accuracy: 0.7869 - val_loss: 0.5753 - val_binary_accuracy: 0.6875\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 2s 184ms/step - loss: 0.3067 - binary_accuracy: 0.8864 - val_loss: 0.4598 - val_binary_accuracy: 0.6875\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 2s 183ms/step - loss: 0.3009 - binary_accuracy: 0.8239 - val_loss: 0.3197 - val_binary_accuracy: 0.8750\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 2s 189ms/step - loss: 0.2609 - binary_accuracy: 0.8381 - val_loss: 0.5015 - val_binary_accuracy: 0.8750\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 2s 192ms/step - loss: 0.2147 - binary_accuracy: 0.9347 - val_loss: 0.4369 - val_binary_accuracy: 0.6875\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 2s 182ms/step - loss: 0.2447 - binary_accuracy: 0.8949 - val_loss: 0.5618 - val_binary_accuracy: 0.8594\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 2s 188ms/step - loss: 0.1890 - binary_accuracy: 0.8807 - val_loss: 0.3968 - val_binary_accuracy: 0.8750\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 2s 191ms/step - loss: 0.1865 - binary_accuracy: 0.9176 - val_loss: 0.3573 - val_binary_accuracy: 0.8750\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 2s 190ms/step - loss: 0.1669 - binary_accuracy: 0.9318 - val_loss: 0.3132 - val_binary_accuracy: 0.8281\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 2s 183ms/step - loss: 0.1507 - binary_accuracy: 0.9432 - val_loss: 0.4051 - val_binary_accuracy: 0.7812\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 2s 186ms/step - loss: 0.1430 - binary_accuracy: 0.9062 - val_loss: 0.9224 - val_binary_accuracy: 0.8438\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 2s 187ms/step - loss: 0.1224 - binary_accuracy: 0.9545 - val_loss: 0.2623 - val_binary_accuracy: 0.8594\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 2s 189ms/step - loss: 0.1583 - binary_accuracy: 0.9517 - val_loss: 0.2867 - val_binary_accuracy: 0.8125\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 2s 190ms/step - loss: 0.1647 - binary_accuracy: 0.9091 - val_loss: 0.3942 - val_binary_accuracy: 0.8594\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 2s 198ms/step - loss: 0.1229 - binary_accuracy: 0.9375 - val_loss: 0.5313 - val_binary_accuracy: 0.8281\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 2s 198ms/step - loss: 0.1018 - binary_accuracy: 0.9517 - val_loss: 0.5879 - val_binary_accuracy: 0.8594\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 2s 201ms/step - loss: 0.0682 - binary_accuracy: 0.9659 - val_loss: 0.2772 - val_binary_accuracy: 0.9219\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 2s 209ms/step - loss: 0.0707 - binary_accuracy: 0.9602 - val_loss: 0.8380 - val_binary_accuracy: 0.8594\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 2s 204ms/step - loss: 0.0643 - binary_accuracy: 0.9688 - val_loss: 0.4443 - val_binary_accuracy: 0.8906\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 2s 200ms/step - loss: 0.0593 - binary_accuracy: 0.9631 - val_loss: 0.8651 - val_binary_accuracy: 0.9219\n"
     ]
    }
   ],
   "source": [
    "h2 = tl_model.fit(\n",
    "    train_datagen,\n",
    "    validation_data=val_datagen,\n",
    "    epochs=fine_tune_epochs,\n",
    "    callbacks=[es_callback, cp_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "010da2d1-dcef-47c8-8011-73bbf31c5b0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2622900605201721"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(h2.history[\"val_loss\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d04b350-b75d-43ed-bfc4-a02f09c5bb45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

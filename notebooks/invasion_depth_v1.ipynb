{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c12c68d-93a1-41af-b05c-e56b17582e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.backend as K\n",
    "import numpy as np\n",
    "import dask as d\n",
    "import os\n",
    "import cv2\n",
    "import multiprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from glob import glob\n",
    "from copy import deepcopy\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.metrics import BinaryAccuracy\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.applications import resnet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a402a73f-b4a9-44ba-8ae5-06641c0668f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_cores = multiprocessing.cpu_count()\n",
    "n_cores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fdc59e17-d035-4e8d-ad5f-ca7adfa21f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fl_tissue_model_tools import data_prep, dev_config, models, defs\n",
    "import fl_tissue_model_tools.preprocessing as prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c960e34-fb3c-463b-8bc5-952730a064dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs = dev_config.get_dev_directories(\"../dev_paths.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77f26842-80d0-4710-ab9f-3f19c1029199",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_data_path = f\"{dirs.data_dir}/invasion_data/development\"\n",
    "# seed = 2049\n",
    "seed = None\n",
    "resnet_inp_shape = (128, 128, 3)\n",
    "# Binary classification -> only need 1 output unit\n",
    "n_outputs = 1\n",
    "val_split = 0.2\n",
    "batch_size = 32\n",
    "frozen_epochs = 50\n",
    "fine_tune_epochs = 50\n",
    "fine_tune_lr = 1e-5\n",
    "class_labels = {\"no_invasion\": 0, \"invasion\": 1}\n",
    "\n",
    "# Early stopping\n",
    "es_criterion = \"val_loss\"\n",
    "es_mode = \"min\"\n",
    "# Update these depending on seriousness of experiment\n",
    "es_patience = 25\n",
    "es_min_delta = 0.0001\n",
    "\n",
    "# Model saving\n",
    "mcp_criterion = \"val_loss\"\n",
    "mcp_mode = \"min\"\n",
    "mcp_best_frozen_weights_path = \"../model_training/resnet50_invasion_depth_demo_v1_best_frozen_weights.h5\"\n",
    "mcp_best_finetune_weights_path = \"../model_training/resnet50_invasion_depth_demo_v1_best_finetune_weights.h5\"\n",
    "mcp_best_only = True\n",
    "# Need to set to True otherwise base model \"layer\" won't save/load properly\n",
    "mcp_weights_only = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a2e6e22-ffed-459e-8895-f1917396c661",
   "metadata": {},
   "source": [
    "# Prep for loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d22b149-c675-4b1c-95e7-909716249d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "rs = np.random.RandomState(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6a69dfe-afa0-41fa-8f26-c8463105bf3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_paths = {v: glob(f\"{root_data_path}/train/{k}/*.tif\") for k, v in class_labels.items()}\n",
    "for k, v in data_paths.items():\n",
    "    rs.shuffle(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "940352be-2f0d-4e8a-845b-8873c3629a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_counts = {k: len(v) for k, v in data_paths.items()}\n",
    "val_counts = {k: round(v * val_split) for k, v in data_counts.items()}\n",
    "train_counts = {k: v - val_counts[k] for k, v in data_counts.items()}\n",
    "train_class_weights = prep.balanced_class_weights_from_counts(train_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c9bdee1-cf3a-4713-800e-750180b6aa06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 454, 1: 102}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e48279d3-14b3-43a7-80c4-fd99ddf41749",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.6129476584022039, 1: 2.7134146341463414}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a3b38c5-6c48-4858-aec1-de470844072a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data_paths = {k: v[val_counts[k]:] for k, v in data_paths.items()}\n",
    "val_data_paths = {k: v[:val_counts[k]] for k, v in data_paths.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4105535b-e87d-4efb-9045-6cc547f17a23",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6aff4bfe-ba64-4a4f-a316-6a7607cc9b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InvasionDataGenerator(Sequence):\n",
    "    def __init__(self, data_paths, class_labels, batch_size, img_shape, random_state, class_weights=None, shuffle=True, augmentation_function=None):\n",
    "        self.data_paths = deepcopy(data_paths)\n",
    "        self.batch_size = batch_size\n",
    "        self.img_shape = img_shape\n",
    "        self.class_labels = deepcopy(class_labels)\n",
    "        self.class_paths = {}\n",
    "        self.class_counts = {}\n",
    "        self.img_paths = []\n",
    "        self.img_labels = []\n",
    "        self.shuffle = shuffle\n",
    "        self.rs = random_state\n",
    "        self.augmentation_function = augmentation_function\n",
    "        self._get_paths_and_counts(data_paths)\n",
    "        self.indices = np.arange(len(self.img_paths), dtype=np.uint)\n",
    "        if class_weights != None:\n",
    "            self.class_weights = deepcopy(class_weights)\n",
    "        else:\n",
    "            self.class_weights = None\n",
    "        self.shuffle_indices()\n",
    "\n",
    "    def __len__(self):\n",
    "        # return len()\n",
    "        return len(self.img_paths) // self.batch_size\n",
    "\n",
    "    def __getitem__(self, index):        \n",
    "        batch_idx_start = index * self.batch_size\n",
    "        batch_idx_end = batch_idx_start + batch_size\n",
    "        batch_indices = self.indices[batch_idx_start: batch_idx_end]\n",
    "\n",
    "        img_paths = [self.img_paths[i] for i in batch_indices]\n",
    "        # Should it be (B,) or (B,1)?\n",
    "        y = np.array([self.img_labels[i] for i in batch_indices])\n",
    "\n",
    "        # Generate data\n",
    "        X = self.prep_images(img_paths)\n",
    "        \n",
    "        if self.augmentation_function != None:\n",
    "            X = self.augmentation_function(X, self.rs, expand_dims=False)\n",
    "        \n",
    "        if self.class_weights != None:\n",
    "            # Weight classes by relative proportions in the training set\n",
    "            w = np.array([self.class_weights[y_] for y_ in y])\n",
    "            return X, y, w\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    \n",
    "    def _get_paths_and_counts(self, data_paths):\n",
    "        self.class_paths = deepcopy(data_paths)\n",
    "        self.class_counts = {c: len(pn) for c, pn in self.class_paths.items()}\n",
    "        for k, v in self.class_paths.items():\n",
    "            # Paths to each image\n",
    "            self.img_paths.extend(v)\n",
    "            # Associate labels with each image path\n",
    "            self.img_labels.extend(list(np.repeat(k, len(v))))\n",
    "            \n",
    "    def _load_img(self, path):\n",
    "        img = cv2.imread(path, cv2.IMREAD_ANYDEPTH)\n",
    "        img = prep.min_max_(cv2.resize(img, self.img_shape, cv2.INTER_LANCZOS4).astype(np.float32), defs.GS_MIN, defs.GS_MAX, defs.TIF_MIN, defs.TIF_MAX)\n",
    "        img = np.repeat(img[:, :, np.newaxis], 3, axis=2)\n",
    "        return img\n",
    "            \n",
    "    def shuffle_indices(self):\n",
    "        # print(\"shuffling\")\n",
    "        self.rs.shuffle(self.indices)\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        self.indices = np.arange(len(self.img_paths), dtype=np.uint)\n",
    "        if self.shuffle == True:\n",
    "            self.shuffle_indices()\n",
    "\n",
    "    def prep_images(self, paths):\n",
    "        imgs = np.array(d.compute((d.delayed(self._load_img)(p) for p in paths))[0])\n",
    "        return resnet50.preprocess_input(imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5d89ed15-f0c8-4469-946c-f0c0e6cbb628",
   "metadata": {},
   "outputs": [],
   "source": [
    "# With class weights\n",
    "train_datagen = InvasionDataGenerator(train_data_paths, class_labels, batch_size, resnet_inp_shape[:2], rs, class_weights=train_class_weights, augmentation_function=prep.augment_imgs)\n",
    "val_datagen = InvasionDataGenerator(val_data_paths, class_labels, batch_size, resnet_inp_shape[:2], rs, class_weights=train_class_weights, augmentation_function=prep.augment_imgs)\n",
    "# # Without class weights\n",
    "# train_datagen = InvasionDataGenerator(train_data_paths, class_labels, batch_size, resnet_inp_shape[:2], rs, augmentation_function=prep.augment_imgs)\n",
    "# val_datagen = InvasionDataGenerator(val_data_paths, class_labels, batch_size, resnet_inp_shape[:2], rs, augmentation_function=prep.augment_imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f50e81cb-bfd6-4ac8-a36d-da6ca500c5f3",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5f59ef1d-0f95-4a14-a92d-327229a104a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b5bbe2fe-8e5b-4e69-a87d-81dcee513b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "tl_model = models.build_ResNet50_TL(\n",
    "    n_outputs,\n",
    "    resnet_inp_shape,\n",
    "    # base_last_layer=\"conv5_block3_out\",\n",
    "    # base_last_layer=\"conv5_block2_out\",\n",
    "    # base_last_layer=\"conv5_block1_out\",\n",
    "    base_last_layer=\"conv4_block6_out\",\n",
    "    # base_last_layer=\"conv4_block5_out\",\n",
    "    # base_last_layer=\"conv4_block4_out\",\n",
    "    # base_last_layer=\"conv4_block3_out\",\n",
    "    # base_last_layer=\"conv4_block2_out\",\n",
    "    # base_last_layer=\"conv4_block1_out\",\n",
    "    # base_last_layer=\"conv3_block4_out\",\n",
    "    # Switch to softmax once n_outputs > 1\n",
    "    output_act=\"sigmoid\",\n",
    "    base_model_trainable=False\n",
    ")\n",
    "# tl_model.compile(optimizer=Adam(), loss=BinaryCrossentropy(), metrics=[BinaryAccuracy()])\n",
    "tl_model.compile(optimizer=Adam(), loss=BinaryCrossentropy(), weighted_metrics=[BinaryAccuracy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "134be685-feda-4ef2-b1f3-e431dcf88233",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 128, 128, 3)]     0         \n",
      "_________________________________________________________________\n",
      "base_model (Functional)      (None, 8, 8, 1024)        8589184   \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 1025      \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 8,590,209\n",
      "Trainable params: 1,025\n",
      "Non-trainable params: 8,589,184\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tl_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "97b6dab5-1ecc-40f3-949e-caeea1ee2b1a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tl_model.get_layer(\"base_model\").summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4a30cd0a-6cef-4e3b-b85a-b95be2cd08b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "es_callback = EarlyStopping(monitor=es_criterion, mode=es_mode, min_delta=es_min_delta, patience=es_patience)\n",
    "cp_callback = ModelCheckpoint(mcp_best_frozen_weights_path, monitor=mcp_criterion, mode=mcp_mode, save_best_only=mcp_best_only, save_weights_only=mcp_weights_only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c38e7b3e-8344-49f4-8c52-70d9ae017acd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "13/13 [==============================] - 11s 316ms/step - loss: 0.6073 - binary_accuracy: 0.6943 - val_loss: 0.5723 - val_binary_accuracy: 0.7491\n",
      "Epoch 2/50\n",
      "13/13 [==============================] - 5s 234ms/step - loss: 0.5396 - binary_accuracy: 0.7507 - val_loss: 0.4892 - val_binary_accuracy: 0.8248\n",
      "Epoch 3/50\n",
      "13/13 [==============================] - 5s 226ms/step - loss: 0.4852 - binary_accuracy: 0.8109 - val_loss: 0.4880 - val_binary_accuracy: 0.8134\n",
      "Epoch 4/50\n",
      "13/13 [==============================] - 4s 218ms/step - loss: 0.4639 - binary_accuracy: 0.8087 - val_loss: 0.4478 - val_binary_accuracy: 0.8389\n",
      "Epoch 5/50\n",
      "13/13 [==============================] - 4s 219ms/step - loss: 0.4596 - binary_accuracy: 0.8118 - val_loss: 0.4384 - val_binary_accuracy: 0.8005\n",
      "Epoch 6/50\n",
      "13/13 [==============================] - 4s 218ms/step - loss: 0.4461 - binary_accuracy: 0.8077 - val_loss: 0.4528 - val_binary_accuracy: 0.7686\n",
      "Epoch 7/50\n",
      "13/13 [==============================] - 4s 196ms/step - loss: 0.4221 - binary_accuracy: 0.8069 - val_loss: 0.4341 - val_binary_accuracy: 0.8218\n",
      "Epoch 8/50\n",
      "13/13 [==============================] - 4s 225ms/step - loss: 0.4226 - binary_accuracy: 0.8201 - val_loss: 0.4276 - val_binary_accuracy: 0.8287\n",
      "Epoch 9/50\n",
      "13/13 [==============================] - 4s 202ms/step - loss: 0.4044 - binary_accuracy: 0.8197 - val_loss: 0.4270 - val_binary_accuracy: 0.8102\n",
      "Epoch 10/50\n",
      "13/13 [==============================] - 4s 204ms/step - loss: 0.4185 - binary_accuracy: 0.8101 - val_loss: 0.4240 - val_binary_accuracy: 0.7862\n",
      "Epoch 11/50\n",
      "13/13 [==============================] - 4s 208ms/step - loss: 0.3976 - binary_accuracy: 0.8239 - val_loss: 0.4127 - val_binary_accuracy: 0.8261\n",
      "Epoch 12/50\n",
      "13/13 [==============================] - 4s 218ms/step - loss: 0.3830 - binary_accuracy: 0.8281 - val_loss: 0.3834 - val_binary_accuracy: 0.8324\n",
      "Epoch 13/50\n",
      "13/13 [==============================] - 5s 224ms/step - loss: 0.3946 - binary_accuracy: 0.8100 - val_loss: 0.4044 - val_binary_accuracy: 0.7888\n",
      "Epoch 14/50\n",
      "13/13 [==============================] - 5s 220ms/step - loss: 0.3983 - binary_accuracy: 0.8215 - val_loss: 0.3860 - val_binary_accuracy: 0.8333\n",
      "Epoch 15/50\n",
      "13/13 [==============================] - 4s 207ms/step - loss: 0.3825 - binary_accuracy: 0.8240 - val_loss: 0.3876 - val_binary_accuracy: 0.8581\n",
      "Epoch 16/50\n",
      "13/13 [==============================] - 4s 220ms/step - loss: 0.3845 - binary_accuracy: 0.8297 - val_loss: 0.3845 - val_binary_accuracy: 0.8333\n",
      "Epoch 17/50\n",
      "13/13 [==============================] - 4s 209ms/step - loss: 0.3828 - binary_accuracy: 0.8322 - val_loss: 0.3997 - val_binary_accuracy: 0.8270\n",
      "Epoch 18/50\n",
      "13/13 [==============================] - 4s 210ms/step - loss: 0.3849 - binary_accuracy: 0.8313 - val_loss: 0.4147 - val_binary_accuracy: 0.8484\n",
      "Epoch 19/50\n",
      "13/13 [==============================] - 4s 214ms/step - loss: 0.3674 - binary_accuracy: 0.8523 - val_loss: 0.4116 - val_binary_accuracy: 0.8125\n",
      "Epoch 20/50\n",
      "13/13 [==============================] - 4s 215ms/step - loss: 0.3945 - binary_accuracy: 0.8147 - val_loss: 0.3574 - val_binary_accuracy: 0.8411\n",
      "Epoch 21/50\n",
      "13/13 [==============================] - 4s 211ms/step - loss: 0.3821 - binary_accuracy: 0.8222 - val_loss: 0.3926 - val_binary_accuracy: 0.8297\n",
      "Epoch 22/50\n",
      "13/13 [==============================] - 4s 232ms/step - loss: 0.3806 - binary_accuracy: 0.8375 - val_loss: 0.3968 - val_binary_accuracy: 0.8259\n",
      "Epoch 23/50\n",
      "13/13 [==============================] - 4s 224ms/step - loss: 0.3786 - binary_accuracy: 0.8131 - val_loss: 0.3409 - val_binary_accuracy: 0.8485\n",
      "Epoch 24/50\n",
      "13/13 [==============================] - 4s 213ms/step - loss: 0.3689 - binary_accuracy: 0.8355 - val_loss: 0.3990 - val_binary_accuracy: 0.8489\n",
      "Epoch 25/50\n",
      "13/13 [==============================] - 4s 195ms/step - loss: 0.3623 - binary_accuracy: 0.8487 - val_loss: 0.4139 - val_binary_accuracy: 0.8058\n",
      "Epoch 26/50\n",
      "13/13 [==============================] - 5s 221ms/step - loss: 0.3542 - binary_accuracy: 0.8296 - val_loss: 0.3553 - val_binary_accuracy: 0.8314\n",
      "Epoch 27/50\n",
      "13/13 [==============================] - 5s 220ms/step - loss: 0.3643 - binary_accuracy: 0.8259 - val_loss: 0.3269 - val_binary_accuracy: 0.8611\n",
      "Epoch 28/50\n",
      "13/13 [==============================] - 4s 208ms/step - loss: 0.3511 - binary_accuracy: 0.8417 - val_loss: 0.3943 - val_binary_accuracy: 0.8307\n",
      "Epoch 29/50\n",
      "13/13 [==============================] - 4s 206ms/step - loss: 0.3865 - binary_accuracy: 0.8209 - val_loss: 0.3521 - val_binary_accuracy: 0.8053\n",
      "Epoch 30/50\n",
      "13/13 [==============================] - 4s 212ms/step - loss: 0.3464 - binary_accuracy: 0.8447 - val_loss: 0.3939 - val_binary_accuracy: 0.7860\n",
      "Epoch 31/50\n",
      "13/13 [==============================] - 4s 203ms/step - loss: 0.3522 - binary_accuracy: 0.8444 - val_loss: 0.3985 - val_binary_accuracy: 0.8032\n",
      "Epoch 32/50\n",
      "13/13 [==============================] - 4s 227ms/step - loss: 0.3622 - binary_accuracy: 0.8404 - val_loss: 0.3807 - val_binary_accuracy: 0.8306\n",
      "Epoch 33/50\n",
      "13/13 [==============================] - 4s 213ms/step - loss: 0.3767 - binary_accuracy: 0.8254 - val_loss: 0.3986 - val_binary_accuracy: 0.8209\n",
      "Epoch 34/50\n",
      "13/13 [==============================] - 4s 211ms/step - loss: 0.3652 - binary_accuracy: 0.8416 - val_loss: 0.4022 - val_binary_accuracy: 0.8333\n",
      "Epoch 35/50\n",
      "13/13 [==============================] - 5s 233ms/step - loss: 0.3658 - binary_accuracy: 0.8304 - val_loss: 0.3772 - val_binary_accuracy: 0.8397\n",
      "Epoch 36/50\n",
      "13/13 [==============================] - 5s 227ms/step - loss: 0.3434 - binary_accuracy: 0.8407 - val_loss: 0.3509 - val_binary_accuracy: 0.8514\n",
      "Epoch 37/50\n",
      "13/13 [==============================] - 4s 217ms/step - loss: 0.3608 - binary_accuracy: 0.8387 - val_loss: 0.4009 - val_binary_accuracy: 0.8261\n",
      "Epoch 38/50\n",
      "13/13 [==============================] - 4s 216ms/step - loss: 0.3579 - binary_accuracy: 0.8294 - val_loss: 0.3739 - val_binary_accuracy: 0.8191\n",
      "Epoch 39/50\n",
      "13/13 [==============================] - 4s 215ms/step - loss: 0.3495 - binary_accuracy: 0.8498 - val_loss: 0.3833 - val_binary_accuracy: 0.8546\n",
      "Epoch 40/50\n",
      "13/13 [==============================] - 5s 233ms/step - loss: 0.3395 - binary_accuracy: 0.8463 - val_loss: 0.3227 - val_binary_accuracy: 0.8870\n",
      "Epoch 41/50\n",
      "13/13 [==============================] - 4s 199ms/step - loss: 0.3538 - binary_accuracy: 0.8317 - val_loss: 0.3684 - val_binary_accuracy: 0.8551\n",
      "Epoch 42/50\n",
      "13/13 [==============================] - 4s 212ms/step - loss: 0.3593 - binary_accuracy: 0.8424 - val_loss: 0.3886 - val_binary_accuracy: 0.8179\n",
      "Epoch 43/50\n",
      "13/13 [==============================] - 5s 215ms/step - loss: 0.3685 - binary_accuracy: 0.8320 - val_loss: 0.3958 - val_binary_accuracy: 0.8416\n",
      "Epoch 44/50\n",
      "13/13 [==============================] - 4s 205ms/step - loss: 0.3381 - binary_accuracy: 0.8514 - val_loss: 0.4242 - val_binary_accuracy: 0.7989\n",
      "Epoch 45/50\n",
      "13/13 [==============================] - 4s 204ms/step - loss: 0.3506 - binary_accuracy: 0.8367 - val_loss: 0.4258 - val_binary_accuracy: 0.8121\n",
      "Epoch 46/50\n",
      "13/13 [==============================] - 4s 206ms/step - loss: 0.3472 - binary_accuracy: 0.8330 - val_loss: 0.4115 - val_binary_accuracy: 0.7917\n",
      "Epoch 47/50\n",
      "13/13 [==============================] - 4s 216ms/step - loss: 0.3550 - binary_accuracy: 0.8314 - val_loss: 0.3761 - val_binary_accuracy: 0.8170\n",
      "Epoch 48/50\n",
      "13/13 [==============================] - 4s 196ms/step - loss: 0.3418 - binary_accuracy: 0.8526 - val_loss: 0.4005 - val_binary_accuracy: 0.8670\n",
      "Epoch 49/50\n",
      "13/13 [==============================] - 4s 200ms/step - loss: 0.3372 - binary_accuracy: 0.8368 - val_loss: 0.3693 - val_binary_accuracy: 0.8403\n",
      "Epoch 50/50\n",
      "13/13 [==============================] - 4s 195ms/step - loss: 0.3439 - binary_accuracy: 0.8420 - val_loss: 0.3768 - val_binary_accuracy: 0.8493\n"
     ]
    }
   ],
   "source": [
    "h1 = tl_model.fit(\n",
    "    train_datagen,\n",
    "    validation_data=val_datagen,\n",
    "    epochs=frozen_epochs,\n",
    "    callbacks=[es_callback, cp_callback],\n",
    "    workers=n_cores\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b5b4515d-5967-4631-a496-1ae1931ab042",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39, 0.32270604372024536)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmin(h1.history[\"val_loss\"]), np.min(h1.history[\"val_loss\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "85cc9124-a9b3-48d2-acb6-2289349c5f43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39, 0.8870266079902649)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(h1.history[\"val_binary_accuracy\"]), np.max(h1.history[\"val_binary_accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d21a2e1-6fb0-4252-97b6-7f395a21aa98",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Load best frozen weights before fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f727e052-d9c1-4613-8582-d93c31e46047",
   "metadata": {},
   "outputs": [],
   "source": [
    "tl_model.load_weights(mcp_best_frozen_weights_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e04b9f7-0220-47e1-88a1-b375166403e7",
   "metadata": {},
   "source": [
    "# Train model (all layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "826188ac-9b5f-4e90-8d9f-2fcaeaa1a98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make base model trainable (leave layers in inference mode)\n",
    "models.toggle_TL_freeze(tl_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9fce61bd-18b7-43e0-96f9-a309c763888f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tl_model.compile(optimizer=Adam(learning_rate=fine_tune_lr), loss=BinaryCrossentropy(), metrics=[BinaryAccuracy()])\n",
    "tl_model.compile(optimizer=Adam(learning_rate=fine_tune_lr), loss=BinaryCrossentropy(), weighted_metrics=[BinaryAccuracy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ff63ccae-1830-4cda-ad44-a8bc1436562c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 128, 128, 3)]     0         \n",
      "_________________________________________________________________\n",
      "base_model (Functional)      (None, 8, 8, 1024)        8589184   \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 1025      \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 8,590,209\n",
      "Trainable params: 8,559,617\n",
      "Non-trainable params: 30,592\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tl_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4bc0da73-0193-4e18-bc4c-f84d86e17a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "es_callback = EarlyStopping(monitor=es_criterion, mode=es_mode, min_delta=es_min_delta, patience=es_patience)\n",
    "cp_callback = ModelCheckpoint(mcp_best_finetune_weights_path, monitor=mcp_criterion, mode=mcp_mode, save_best_only=mcp_best_only, save_weights_only=mcp_weights_only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "05c2c008-c5fe-473f-a209-9da1e56b64b4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "13/13 [==============================] - 10s 270ms/step - loss: 0.3603 - binary_accuracy: 0.8408 - val_loss: 0.3524 - val_binary_accuracy: 0.8167\n",
      "Epoch 2/50\n",
      "13/13 [==============================] - 2s 180ms/step - loss: 0.3450 - binary_accuracy: 0.8229 - val_loss: 0.4386 - val_binary_accuracy: 0.8236\n",
      "Epoch 3/50\n",
      "13/13 [==============================] - 2s 184ms/step - loss: 0.3199 - binary_accuracy: 0.8656 - val_loss: 0.4028 - val_binary_accuracy: 0.8464\n",
      "Epoch 4/50\n",
      "13/13 [==============================] - 2s 182ms/step - loss: 0.3193 - binary_accuracy: 0.8613 - val_loss: 0.3996 - val_binary_accuracy: 0.8324\n",
      "Epoch 5/50\n",
      "13/13 [==============================] - 2s 182ms/step - loss: 0.3214 - binary_accuracy: 0.8638 - val_loss: 0.3974 - val_binary_accuracy: 0.8125\n",
      "Epoch 6/50\n",
      "13/13 [==============================] - 2s 182ms/step - loss: 0.3056 - binary_accuracy: 0.8588 - val_loss: 0.3979 - val_binary_accuracy: 0.8713\n",
      "Epoch 7/50\n",
      "13/13 [==============================] - 2s 183ms/step - loss: 0.2903 - binary_accuracy: 0.8786 - val_loss: 0.3676 - val_binary_accuracy: 0.8721\n",
      "Epoch 8/50\n",
      "13/13 [==============================] - 2s 182ms/step - loss: 0.2796 - binary_accuracy: 0.8952 - val_loss: 0.4142 - val_binary_accuracy: 0.8194\n",
      "Epoch 9/50\n",
      "13/13 [==============================] - 2s 184ms/step - loss: 0.2429 - binary_accuracy: 0.9017 - val_loss: 0.3597 - val_binary_accuracy: 0.8324\n",
      "Epoch 10/50\n",
      "13/13 [==============================] - 2s 183ms/step - loss: 0.2521 - binary_accuracy: 0.8941 - val_loss: 0.4313 - val_binary_accuracy: 0.8272\n",
      "Epoch 11/50\n",
      "13/13 [==============================] - 2s 184ms/step - loss: 0.2684 - binary_accuracy: 0.8882 - val_loss: 0.3770 - val_binary_accuracy: 0.8583\n",
      "Epoch 12/50\n",
      "13/13 [==============================] - 2s 183ms/step - loss: 0.2444 - binary_accuracy: 0.9011 - val_loss: 0.4319 - val_binary_accuracy: 0.8143\n",
      "Epoch 13/50\n",
      "13/13 [==============================] - 2s 185ms/step - loss: 0.2237 - binary_accuracy: 0.9193 - val_loss: 0.4463 - val_binary_accuracy: 0.8556\n",
      "Epoch 14/50\n",
      "13/13 [==============================] - 2s 183ms/step - loss: 0.2268 - binary_accuracy: 0.9137 - val_loss: 0.4685 - val_binary_accuracy: 0.8387\n",
      "Epoch 15/50\n",
      "13/13 [==============================] - 2s 189ms/step - loss: 0.2164 - binary_accuracy: 0.9106 - val_loss: 0.4060 - val_binary_accuracy: 0.8958\n",
      "Epoch 16/50\n",
      "13/13 [==============================] - 2s 187ms/step - loss: 0.1826 - binary_accuracy: 0.9484 - val_loss: 0.3973 - val_binary_accuracy: 0.8454\n",
      "Epoch 17/50\n",
      "13/13 [==============================] - 2s 186ms/step - loss: 0.2238 - binary_accuracy: 0.9147 - val_loss: 0.4744 - val_binary_accuracy: 0.8286\n",
      "Epoch 18/50\n",
      "13/13 [==============================] - 2s 188ms/step - loss: 0.1939 - binary_accuracy: 0.9292 - val_loss: 0.2900 - val_binary_accuracy: 0.8778\n",
      "Epoch 19/50\n",
      "13/13 [==============================] - 2s 187ms/step - loss: 0.1826 - binary_accuracy: 0.9339 - val_loss: 0.3140 - val_binary_accuracy: 0.8684\n",
      "Epoch 20/50\n",
      "13/13 [==============================] - 2s 184ms/step - loss: 0.1604 - binary_accuracy: 0.9492 - val_loss: 0.5134 - val_binary_accuracy: 0.8406\n",
      "Epoch 21/50\n",
      "13/13 [==============================] - 2s 187ms/step - loss: 0.1709 - binary_accuracy: 0.9378 - val_loss: 0.4520 - val_binary_accuracy: 0.8750\n",
      "Epoch 22/50\n",
      "13/13 [==============================] - 2s 187ms/step - loss: 0.1540 - binary_accuracy: 0.9588 - val_loss: 0.4733 - val_binary_accuracy: 0.8314\n",
      "Epoch 23/50\n",
      "13/13 [==============================] - 2s 186ms/step - loss: 0.1835 - binary_accuracy: 0.9181 - val_loss: 0.5227 - val_binary_accuracy: 0.8431\n",
      "Epoch 24/50\n",
      "13/13 [==============================] - 3s 214ms/step - loss: 0.1450 - binary_accuracy: 0.9535 - val_loss: 0.2485 - val_binary_accuracy: 0.8935\n",
      "Epoch 25/50\n",
      "13/13 [==============================] - 3s 195ms/step - loss: 0.1420 - binary_accuracy: 0.9510 - val_loss: 0.5495 - val_binary_accuracy: 0.8243\n",
      "Epoch 26/50\n",
      "13/13 [==============================] - 3s 198ms/step - loss: 0.1225 - binary_accuracy: 0.9567 - val_loss: 0.5516 - val_binary_accuracy: 0.8741\n",
      "Epoch 27/50\n",
      "13/13 [==============================] - 2s 188ms/step - loss: 0.1378 - binary_accuracy: 0.9569 - val_loss: 0.4936 - val_binary_accuracy: 0.8528\n",
      "Epoch 28/50\n",
      "13/13 [==============================] - 3s 193ms/step - loss: 0.0831 - binary_accuracy: 0.9756 - val_loss: 0.5459 - val_binary_accuracy: 0.8493\n",
      "Epoch 29/50\n",
      "13/13 [==============================] - 3s 193ms/step - loss: 0.0980 - binary_accuracy: 0.9786 - val_loss: 0.5644 - val_binary_accuracy: 0.8741\n",
      "Epoch 30/50\n",
      "13/13 [==============================] - 3s 205ms/step - loss: 0.1221 - binary_accuracy: 0.9578 - val_loss: 0.5595 - val_binary_accuracy: 0.8493\n",
      "Epoch 31/50\n",
      "13/13 [==============================] - 3s 201ms/step - loss: 0.1265 - binary_accuracy: 0.9351 - val_loss: 0.5735 - val_binary_accuracy: 0.8324\n",
      "Epoch 32/50\n",
      "13/13 [==============================] - 3s 216ms/step - loss: 0.0832 - binary_accuracy: 0.9760 - val_loss: 0.6710 - val_binary_accuracy: 0.8463\n",
      "Epoch 33/50\n",
      "13/13 [==============================] - 3s 228ms/step - loss: 0.1058 - binary_accuracy: 0.9686 - val_loss: 0.6637 - val_binary_accuracy: 0.7797\n",
      "Epoch 34/50\n",
      "13/13 [==============================] - 3s 235ms/step - loss: 0.0783 - binary_accuracy: 0.9740 - val_loss: 0.5907 - val_binary_accuracy: 0.8841\n",
      "Epoch 35/50\n",
      "13/13 [==============================] - 3s 249ms/step - loss: 0.0620 - binary_accuracy: 0.9783 - val_loss: 0.1929 - val_binary_accuracy: 0.9157\n",
      "Epoch 36/50\n",
      "13/13 [==============================] - 3s 237ms/step - loss: 0.0649 - binary_accuracy: 0.9788 - val_loss: 0.6637 - val_binary_accuracy: 0.7415\n",
      "Epoch 37/50\n",
      "13/13 [==============================] - 3s 225ms/step - loss: 0.0522 - binary_accuracy: 0.9926 - val_loss: 0.9049 - val_binary_accuracy: 0.7380\n",
      "Epoch 38/50\n",
      "13/13 [==============================] - 3s 218ms/step - loss: 0.0630 - binary_accuracy: 0.9792 - val_loss: 0.6344 - val_binary_accuracy: 0.8854\n",
      "Epoch 39/50\n",
      "13/13 [==============================] - 3s 228ms/step - loss: 0.0378 - binary_accuracy: 0.9956 - val_loss: 0.6146 - val_binary_accuracy: 0.8120\n",
      "Epoch 40/50\n",
      "13/13 [==============================] - 3s 229ms/step - loss: 0.0482 - binary_accuracy: 0.9831 - val_loss: 0.5957 - val_binary_accuracy: 0.8972\n",
      "Epoch 41/50\n",
      "13/13 [==============================] - 3s 235ms/step - loss: 0.0449 - binary_accuracy: 0.9848 - val_loss: 0.9131 - val_binary_accuracy: 0.8135\n",
      "Epoch 42/50\n",
      "13/13 [==============================] - 3s 224ms/step - loss: 0.0289 - binary_accuracy: 0.9971 - val_loss: 0.3622 - val_binary_accuracy: 0.8883\n",
      "Epoch 43/50\n",
      "13/13 [==============================] - 3s 215ms/step - loss: 0.0338 - binary_accuracy: 0.9890 - val_loss: 0.8121 - val_binary_accuracy: 0.8254\n",
      "Epoch 44/50\n",
      "13/13 [==============================] - 3s 220ms/step - loss: 0.0323 - binary_accuracy: 0.9834 - val_loss: 0.9775 - val_binary_accuracy: 0.7935\n",
      "Epoch 45/50\n",
      "13/13 [==============================] - 3s 213ms/step - loss: 0.0321 - binary_accuracy: 0.9956 - val_loss: 0.9227 - val_binary_accuracy: 0.7917\n",
      "Epoch 46/50\n",
      "13/13 [==============================] - 3s 230ms/step - loss: 0.0185 - binary_accuracy: 0.9985 - val_loss: 0.8673 - val_binary_accuracy: 0.8685\n",
      "Epoch 47/50\n",
      "13/13 [==============================] - 3s 227ms/step - loss: 0.0180 - binary_accuracy: 0.9971 - val_loss: 0.8780 - val_binary_accuracy: 0.8498\n",
      "Epoch 48/50\n",
      "13/13 [==============================] - 3s 217ms/step - loss: 0.0225 - binary_accuracy: 0.9889 - val_loss: 0.9842 - val_binary_accuracy: 0.7998\n",
      "Epoch 49/50\n",
      "13/13 [==============================] - 3s 230ms/step - loss: 0.0234 - binary_accuracy: 0.9956 - val_loss: 0.8984 - val_binary_accuracy: 0.8591\n",
      "Epoch 50/50\n",
      "13/13 [==============================] - 3s 237ms/step - loss: 0.0174 - binary_accuracy: 0.9905 - val_loss: 0.7119 - val_binary_accuracy: 0.8103\n"
     ]
    }
   ],
   "source": [
    "h2 = tl_model.fit(\n",
    "    train_datagen,\n",
    "    validation_data=val_datagen,\n",
    "    epochs=fine_tune_epochs,\n",
    "    callbacks=[es_callback, cp_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "010da2d1-dcef-47c8-8011-73bbf31c5b0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34, 0.19291287660598755)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmin(h2.history[\"val_loss\"]), np.min(h2.history[\"val_loss\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1d04b350-b75d-43ed-bfc4-a02f09c5bb45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34, 0.9156945943832397)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(h2.history[\"val_binary_accuracy\"]), np.max(h2.history[\"val_binary_accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51be6fcc-fc03-4ee3-9304-0227c8a48054",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

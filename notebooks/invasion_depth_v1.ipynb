{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c12c68d-93a1-41af-b05c-e56b17582e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.backend as K\n",
    "import numpy as np\n",
    "import dask as d\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from glob import glob\n",
    "from copy import deepcopy\n",
    "from collections import defaultdict\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.metrics import BinaryAccuracy\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.applications import resnet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fdc59e17-d035-4e8d-ad5f-ca7adfa21f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fl_tissue_model_tools import data_prep, dev_config, models, defs\n",
    "import fl_tissue_model_tools.preprocessing as prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c960e34-fb3c-463b-8bc5-952730a064dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs = dev_config.get_dev_directories(\"../dev_paths.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77f26842-80d0-4710-ab9f-3f19c1029199",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_data_path = f\"{dirs.data_dir}/invasion_data/development\"\n",
    "resnet_inp_shape = (128, 128, 3)\n",
    "# Binary classification -> only need 1 output unit\n",
    "n_outputs = 1\n",
    "val_split = 0.2\n",
    "batch_size = 32\n",
    "frozen_epochs = 20\n",
    "fine_tune_epochs = 20\n",
    "fine_tune_lr = 1e-5\n",
    "seed = 20394\n",
    "class_labels = {\"no_invasion\": 0, \"invasion\": 1}\n",
    "\n",
    "# Early stopping\n",
    "es_criterion = \"val_loss\"\n",
    "es_mode = \"min\"\n",
    "# Update these depending on seriousness of experiment\n",
    "es_patience = 10\n",
    "es_min_delta = 0.0001\n",
    "\n",
    "# Model saving\n",
    "cp_criterion = \"val_loss\"\n",
    "cp_mode = \"min\"\n",
    "cp_frozen_filepath = \"../model_training/resnet50_invasion_depth_demo_v1_best_frozen_weights.h5\"\n",
    "cp_fine_tune_filepath = \"../model_training/resnet50_invasion_depth_demo_v1_best_fine_tune_weights.h5\"\n",
    "cp_best_only = True\n",
    "# Need to set to True otherwise base model \"layer\" won't save/load properly\n",
    "cp_weights_only = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da805bd0-d5c8-4dc4-a139-3a36eb018818",
   "metadata": {},
   "outputs": [],
   "source": [
    "def balanced_class_weights_from_counts(d):\n",
    "    n = np.sum(list(d.values()))\n",
    "    n_c = len(d.keys())\n",
    "    weights = {}\n",
    "    for ci, n_ci in d.items():\n",
    "        weights[ci] = n / (n_c * n_ci)\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a2e6e22-ffed-459e-8895-f1917396c661",
   "metadata": {},
   "source": [
    "# Prep for loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d22b149-c675-4b1c-95e7-909716249d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "rs = np.random.RandomState(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6a69dfe-afa0-41fa-8f26-c8463105bf3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_paths = {v: glob(f\"{root_data_path}/train/{k}/*.tif\") for k, v in class_labels.items()}\n",
    "for k, v in data_paths.items():\n",
    "    rs.shuffle(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "940352be-2f0d-4e8a-845b-8873c3629a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_counts = {k: len(v) for k, v in data_paths.items()}\n",
    "val_counts = {k: round(v * val_split) for k, v in data_counts.items()}\n",
    "train_counts = {k: v - val_counts[k] for k, v in data_counts.items()}\n",
    "train_class_weights = balanced_class_weights_from_counts(train_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c9bdee1-cf3a-4713-800e-750180b6aa06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 390, 1: 39}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e48279d3-14b3-43a7-80c4-fd99ddf41749",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.5496794871794872, 1: 5.532258064516129}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a3b38c5-6c48-4858-aec1-de470844072a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data_paths = {k: v[val_counts[k]:] for k, v in data_paths.items()}\n",
    "val_data_paths = {k: v[:val_counts[k]] for k, v in data_paths.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4105535b-e87d-4efb-9045-6cc547f17a23",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6aff4bfe-ba64-4a4f-a316-6a7607cc9b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InvasionDataGenerator(Sequence):\n",
    "    def __init__(self, data_paths, class_labels, batch_size, img_shape, random_state, class_weights=None, shuffle=True, augmentation_function=None):\n",
    "        self.data_paths = deepcopy(data_paths)\n",
    "        self.batch_size = batch_size\n",
    "        self.img_shape = img_shape\n",
    "        self.class_labels = deepcopy(class_labels)\n",
    "        self.class_paths = {}\n",
    "        self.class_counts = {}\n",
    "        self.img_paths = []\n",
    "        self.img_labels = []\n",
    "        self.shuffle = shuffle\n",
    "        self.rs = random_state\n",
    "        self.augmentation_function = augmentation_function\n",
    "        self._get_paths_and_counts(data_paths)\n",
    "        self.indices = np.arange(len(self.img_paths), dtype=np.uint)\n",
    "        if class_weights != None:\n",
    "            self.class_weights = deepcopy(class_weights)\n",
    "        else:\n",
    "            self.class_weights = None\n",
    "        self.shuffle_indices()\n",
    "\n",
    "    def __len__(self):\n",
    "        # return len()\n",
    "        return len(self.img_paths) // self.batch_size\n",
    "\n",
    "    def __getitem__(self, index):        \n",
    "        batch_idx_start = index * self.batch_size\n",
    "        batch_idx_end = batch_idx_start + batch_size\n",
    "        batch_indices = self.indices[batch_idx_start: batch_idx_end]\n",
    "\n",
    "        img_paths = [self.img_paths[i] for i in batch_indices]\n",
    "        # Should it be (B,) or (B,1)?\n",
    "        y = np.array([self.img_labels[i] for i in batch_indices])\n",
    "\n",
    "        # Generate data\n",
    "        X = self.prep_images(img_paths)\n",
    "        \n",
    "        if self.augmentation_function != None:\n",
    "            X = self.augmentation_function(X, self.rs, expand_dims=False)\n",
    "        \n",
    "        if self.class_weights != None:\n",
    "            # Weight classes by relative proportions in the training set\n",
    "            w = np.array([self.class_weights[y_] for y_ in y])\n",
    "            return X, y, w\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    \n",
    "    def _get_paths_and_counts(self, data_paths):\n",
    "        self.class_paths = deepcopy(data_paths)\n",
    "        self.class_counts = {c: len(pn) for c, pn in self.class_paths.items()}\n",
    "        for k, v in self.class_paths.items():\n",
    "            # Paths to each image\n",
    "            self.img_paths.extend(v)\n",
    "            # Associate labels with each image path\n",
    "            self.img_labels.extend(list(np.repeat(k, len(v))))\n",
    "            \n",
    "    def _load_img(self, path):\n",
    "        img = cv2.imread(path, cv2.IMREAD_ANYDEPTH)\n",
    "        img = prep.min_max_(cv2.resize(img, self.img_shape, cv2.INTER_LANCZOS4).astype(np.float32), defs.GS_MIN, defs.GS_MAX, defs.TIF_MIN, defs.TIF_MAX)\n",
    "        img = np.repeat(img[:, :, np.newaxis], 3, axis=2)\n",
    "        return img\n",
    "            \n",
    "    def shuffle_indices(self):\n",
    "        # print(\"shuffling\")\n",
    "        self.rs.shuffle(self.indices)\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        self.indices = np.arange(len(self.img_paths), dtype=np.uint)\n",
    "        if self.shuffle == True:\n",
    "            self.shuffle_indices()\n",
    "\n",
    "    def prep_images(self, paths):\n",
    "        imgs = np.array(d.compute((d.delayed(self._load_img)(p) for p in paths))[0])\n",
    "        return resnet50.preprocess_input(imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5d89ed15-f0c8-4469-946c-f0c0e6cbb628",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # With class weights\n",
    "train_datagen = InvasionDataGenerator(train_data_paths, class_labels, batch_size, resnet_inp_shape[:2], rs, class_weights=train_class_weights, augmentation_function=prep.augment_imgs)\n",
    "val_datagen = InvasionDataGenerator(val_data_paths, class_labels, batch_size, resnet_inp_shape[:2], rs, class_weights=train_class_weights, augmentation_function=prep.augment_imgs)\n",
    "# Without class weights\n",
    "# train_datagen = InvasionDataGenerator(train_data_paths, class_labels, batch_size, resnet_inp_shape[:2], rs, augmentation_function=prep.augment_imgs)\n",
    "# val_datagen = InvasionDataGenerator(val_data_paths, class_labels, batch_size, resnet_inp_shape[:2], rs, augmentation_function=prep.augment_imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f50e81cb-bfd6-4ac8-a36d-da6ca500c5f3",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5f59ef1d-0f95-4a14-a92d-327229a104a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b5bbe2fe-8e5b-4e69-a87d-81dcee513b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "tl_model = models.build_ResNet50_TL(\n",
    "    n_outputs,\n",
    "    resnet_inp_shape,\n",
    "    base_last_layer=\"conv5_block3_out\",\n",
    "    # base_last_layer=\"conv5_block2_out\",\n",
    "    # base_last_layer=\"conv5_block1_out\",\n",
    "    # base_last_layer=\"conv4_block6_out\",\n",
    "    # base_last_layer=\"conv4_block3_out\",\n",
    "    # base_last_layer=\"conv4_block1_out\",\n",
    "    # base_last_layer=\"conv3_block4_out\",\n",
    "    # Switch to softmax once n_outputs > 1\n",
    "    output_act=\"sigmoid\",\n",
    "    base_model_trainable=False\n",
    ")\n",
    "tl_model.compile(optimizer=Adam(), loss=BinaryCrossentropy(), metrics=[BinaryAccuracy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "134be685-feda-4ef2-b1f3-e431dcf88233",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 128, 128, 3)]     0         \n",
      "_________________________________________________________________\n",
      "base_model (Functional)      (None, 4, 4, 2048)        23587712  \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 2049      \n",
      "=================================================================\n",
      "Total params: 23,589,761\n",
      "Trainable params: 2,049\n",
      "Non-trainable params: 23,587,712\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tl_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4a30cd0a-6cef-4e3b-b85a-b95be2cd08b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "es_callback = EarlyStopping(monitor=es_criterion, mode=es_mode, min_delta=es_min_delta, patience=es_patience)\n",
    "cp_callback = ModelCheckpoint(cp_frozen_filepath, monitor=cp_criterion, mode=cp_mode, save_best_only=cp_best_only, save_weights_only=cp_weights_only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c38e7b3e-8344-49f4-8c52-70d9ae017acd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "10/10 [==============================] - 9s 325ms/step - loss: 0.7157 - binary_accuracy: 0.5875 - val_loss: 0.6037 - val_binary_accuracy: 0.5781\n",
      "Epoch 2/20\n",
      " 8/10 [=======================>......] - ETA: 0s - loss: 0.5014 - binary_accuracy: 0.7188"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [18]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m h1 \u001b[38;5;241m=\u001b[39m \u001b[43mtl_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_datagen\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_datagen\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfrozen_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mes_callback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcp_callback\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\fogg-lab-tissue-model-analysis-tools-env\\lib\\site-packages\\keras\\engine\\training.py:1184\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1177\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1178\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   1179\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   1180\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[0;32m   1181\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m   1182\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m   1183\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1184\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1185\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1186\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\fogg-lab-tissue-model-analysis-tools-env\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:885\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    882\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    884\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 885\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    887\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    888\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\fogg-lab-tissue-model-analysis-tools-env\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:917\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    914\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    915\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    916\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 917\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateless_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    918\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    919\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    920\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    921\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\fogg-lab-tissue-model-analysis-tools-env\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3039\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3036\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   3037\u001b[0m   (graph_function,\n\u001b[0;32m   3038\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3039\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3040\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\fogg-lab-tissue-model-analysis-tools-env\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1963\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1959\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1960\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1961\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1962\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1963\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1964\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1965\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1966\u001b[0m     args,\n\u001b[0;32m   1967\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1968\u001b[0m     executing_eagerly)\n\u001b[0;32m   1969\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\fogg-lab-tissue-model-analysis-tools-env\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:591\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    589\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    590\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 591\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    592\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    593\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    594\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    595\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    596\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    597\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    598\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    599\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    600\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    603\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    604\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\fogg-lab-tissue-model-analysis-tools-env\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:59\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     58\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 59\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     60\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     62\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "h1 = tl_model.fit(\n",
    "    train_datagen,\n",
    "    validation_data=val_datagen,\n",
    "    epochs=frozen_epochs,\n",
    "    callbacks=[es_callback, cp_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d21a2e1-6fb0-4252-97b6-7f395a21aa98",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Load best frozen weights before fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f727e052-d9c1-4613-8582-d93c31e46047",
   "metadata": {},
   "outputs": [],
   "source": [
    "tl_model.load_weights(cp_frozen_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e04b9f7-0220-47e1-88a1-b375166403e7",
   "metadata": {},
   "source": [
    "# Train model (all layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826188ac-9b5f-4e90-8d9f-2fcaeaa1a98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make base model trainable (leave layers in inference mode)\n",
    "models.toggle_TL_freeze(tl_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fce61bd-18b7-43e0-96f9-a309c763888f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tl_model.compile(optimizer=Adam(learning_rate=fine_tune_lr), loss=BinaryCrossentropy(), metrics=[BinaryAccuracy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff63ccae-1830-4cda-ad44-a8bc1436562c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tl_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc0da73-0193-4e18-bc4c-f84d86e17a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "es_callback = EarlyStopping(monitor=es_criterion, mode=es_mode, min_delta=es_min_delta, patience=es_patience)\n",
    "cp_callback = ModelCheckpoint(cp_fine_tune_filepath, monitor=cp_criterion, mode=cp_mode, save_best_only=cp_best_only, save_weights_only=cp_weights_only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c2c008-c5fe-473f-a209-9da1e56b64b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "h2 = tl_model.fit(\n",
    "    train_datagen,\n",
    "    validation_data=val_datagen,\n",
    "    epochs=fine_tune_epochs,\n",
    "    callbacks=[es_callback, cp_callback]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c12c68d-93a1-41af-b05c-e56b17582e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.backend as K\n",
    "import numpy as np\n",
    "import dask as d\n",
    "import os\n",
    "import cv2\n",
    "import json\n",
    "import multiprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from glob import glob\n",
    "from copy import deepcopy\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.metrics import BinaryAccuracy\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.applications import resnet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a402a73f-b4a9-44ba-8ae5-06641c0668f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_cores = multiprocessing.cpu_count()\n",
    "n_cores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fdc59e17-d035-4e8d-ad5f-ca7adfa21f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fl_tissue_model_tools import data_prep, dev_config, models, defs\n",
    "import fl_tissue_model_tools.preprocessing as prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c960e34-fb3c-463b-8bc5-952730a064dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs = dev_config.get_dev_directories(\"../dev_paths.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911406d1-d145-445f-a442-645b5138c60e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Set up model training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d3b1db8-45d3-4882-bd10-002c0c5f1f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../model_training/invasion_depth_training_values.json\", 'r') as fp:\n",
    "       training_values = json.load(fp)\n",
    "training_values[\"rs_seed\"] = None if (training_values[\"rs_seed\"] == \"None\") else training_values[\"rs_seed\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75096603-49df-41d3-8d1d-de1801ba8f1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 32,\n",
       " 'frozen_epochs': 50,\n",
       " 'fine_tune_epochs': 50,\n",
       " 'val_split': 0.2,\n",
       " 'early_stopping_patience': 25,\n",
       " 'early_stopping_min_delta': 0.0001,\n",
       " 'rs_seed': None}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77f26842-80d0-4710-ab9f-3f19c1029199",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_data_path = f\"{dirs.data_dir}/invasion_data/development\"\n",
    "model_training_path = f\"{dirs.analysis_dir}/resnet50_invasion_model\"\n",
    "demo_model_training_path = f\"{model_training_path}/demo_v1\"\n",
    "mcp_best_frozen_weights_file = f\"{demo_model_training_path}/best_frozen_weights.h5\"\n",
    "mcp_best_finetune_weights_file = f\"{demo_model_training_path}/best_finetune_weights.h5\"\n",
    "\n",
    "\n",
    "### General training parameters ###\n",
    "resnet_inp_shape = (128, 128, 3)\n",
    "# Binary classification -> only need 1 output unit\n",
    "n_outputs = 1\n",
    "seed = training_values[\"rs_seed\"]\n",
    "val_split = training_values[\"val_split\"]\n",
    "batch_size = training_values[\"batch_size\"]\n",
    "frozen_epochs = training_values[\"frozen_epochs\"]\n",
    "fine_tune_epochs = training_values[\"fine_tune_epochs\"]\n",
    "fine_tune_lr = 1e-5\n",
    "class_labels = {\"no_invasion\": 0, \"invasion\": 1}\n",
    "\n",
    "\n",
    "### Early stopping ###\n",
    "es_criterion = \"val_loss\"\n",
    "es_mode = \"min\"\n",
    "# Update these depending on seriousness of experiment\n",
    "es_patience = training_values[\"early_stopping_patience\"]\n",
    "es_min_delta = training_values[\"early_stopping_min_delta\"]\n",
    "\n",
    "\n",
    "### Model saving ###\n",
    "mcp_criterion = \"val_loss\"\n",
    "mcp_mode = \"min\"\n",
    "mcp_best_only = True\n",
    "# Need to set to True otherwise base model \"layer\" won't save/load properly\n",
    "mcp_weights_only = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd546ce2-154b-4f0b-8010-f581516a6597",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_prep.make_dir(demo_model_training_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a2e6e22-ffed-459e-8895-f1917396c661",
   "metadata": {},
   "source": [
    "# Prep for loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d22b149-c675-4b1c-95e7-909716249d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "rs = np.random.RandomState(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c6a69dfe-afa0-41fa-8f26-c8463105bf3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_paths = {v: glob(f\"{root_data_path}/train/{k}/*.tif\") for k, v in class_labels.items()}\n",
    "for k, v in data_paths.items():\n",
    "    rs.shuffle(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "940352be-2f0d-4e8a-845b-8873c3629a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_counts = {k: len(v) for k, v in data_paths.items()}\n",
    "val_counts = {k: round(v * val_split) for k, v in data_counts.items()}\n",
    "train_counts = {k: v - val_counts[k] for k, v in data_counts.items()}\n",
    "train_class_weights = prep.balanced_class_weights_from_counts(train_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1c9bdee1-cf3a-4713-800e-750180b6aa06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 454, 1: 102}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e48279d3-14b3-43a7-80c4-fd99ddf41749",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.6129476584022039, 1: 2.7134146341463414}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0a3b38c5-6c48-4858-aec1-de470844072a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data_paths = {k: v[val_counts[k]:] for k, v in data_paths.items()}\n",
    "val_data_paths = {k: v[:val_counts[k]] for k, v in data_paths.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4105535b-e87d-4efb-9045-6cc547f17a23",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6aff4bfe-ba64-4a4f-a316-6a7607cc9b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InvasionDataGenerator(Sequence):\n",
    "    def __init__(self, data_paths, class_labels, batch_size, img_shape, random_state, class_weights=None, shuffle=True, augmentation_function=None):\n",
    "        self.data_paths = deepcopy(data_paths)\n",
    "        self.batch_size = batch_size\n",
    "        self.img_shape = img_shape\n",
    "        self.class_labels = deepcopy(class_labels)\n",
    "        self.class_paths = {}\n",
    "        self.class_counts = {}\n",
    "        self.img_paths = []\n",
    "        self.img_labels = []\n",
    "        self.shuffle = shuffle\n",
    "        self.rs = random_state\n",
    "        self.augmentation_function = augmentation_function\n",
    "        self._get_paths_and_counts(data_paths)\n",
    "        self.indices = np.arange(len(self.img_paths), dtype=np.uint)\n",
    "        if class_weights != None:\n",
    "            self.class_weights = deepcopy(class_weights)\n",
    "        else:\n",
    "            self.class_weights = None\n",
    "        self.shuffle_indices()\n",
    "\n",
    "    def __len__(self):\n",
    "        # return len()\n",
    "        return len(self.img_paths) // self.batch_size\n",
    "\n",
    "    def __getitem__(self, index):        \n",
    "        batch_idx_start = index * self.batch_size\n",
    "        batch_idx_end = batch_idx_start + batch_size\n",
    "        batch_indices = self.indices[batch_idx_start: batch_idx_end]\n",
    "\n",
    "        img_paths = [self.img_paths[i] for i in batch_indices]\n",
    "        # Should it be (B,) or (B,1)?\n",
    "        y = np.array([self.img_labels[i] for i in batch_indices])\n",
    "\n",
    "        # Generate data\n",
    "        X = self.prep_images(img_paths)\n",
    "        \n",
    "        if self.augmentation_function != None:\n",
    "            X = self.augmentation_function(X, self.rs, expand_dims=False)\n",
    "        \n",
    "        if self.class_weights != None:\n",
    "            # Weight classes by relative proportions in the training set\n",
    "            w = np.array([self.class_weights[y_] for y_ in y])\n",
    "            return X, y, w\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    \n",
    "    def _get_paths_and_counts(self, data_paths):\n",
    "        self.class_paths = deepcopy(data_paths)\n",
    "        self.class_counts = {c: len(pn) for c, pn in self.class_paths.items()}\n",
    "        for k, v in self.class_paths.items():\n",
    "            # Paths to each image\n",
    "            self.img_paths.extend(v)\n",
    "            # Associate labels with each image path\n",
    "            self.img_labels.extend(list(np.repeat(k, len(v))))\n",
    "            \n",
    "    def _load_img(self, path):\n",
    "        img = cv2.imread(path, cv2.IMREAD_ANYDEPTH)\n",
    "        img = prep.min_max_(cv2.resize(img, self.img_shape, cv2.INTER_LANCZOS4).astype(np.float32), defs.GS_MIN, defs.GS_MAX, defs.TIF_MIN, defs.TIF_MAX)\n",
    "        img = np.repeat(img[:, :, np.newaxis], 3, axis=2)\n",
    "        return img\n",
    "            \n",
    "    def shuffle_indices(self):\n",
    "        # print(\"shuffling\")\n",
    "        self.rs.shuffle(self.indices)\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        self.indices = np.arange(len(self.img_paths), dtype=np.uint)\n",
    "        if self.shuffle == True:\n",
    "            self.shuffle_indices()\n",
    "\n",
    "    def prep_images(self, paths):\n",
    "        imgs = np.array(d.compute((d.delayed(self._load_img)(p) for p in paths))[0])\n",
    "        return resnet50.preprocess_input(imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5d89ed15-f0c8-4469-946c-f0c0e6cbb628",
   "metadata": {},
   "outputs": [],
   "source": [
    "# With class weights\n",
    "train_datagen = InvasionDataGenerator(train_data_paths, class_labels, batch_size, resnet_inp_shape[:2], rs, class_weights=train_class_weights, augmentation_function=prep.augment_imgs)\n",
    "val_datagen = InvasionDataGenerator(val_data_paths, class_labels, batch_size, resnet_inp_shape[:2], rs, class_weights=train_class_weights, augmentation_function=prep.augment_imgs)\n",
    "# # Without class weights\n",
    "# train_datagen = InvasionDataGenerator(train_data_paths, class_labels, batch_size, resnet_inp_shape[:2], rs, augmentation_function=prep.augment_imgs)\n",
    "# val_datagen = InvasionDataGenerator(val_data_paths, class_labels, batch_size, resnet_inp_shape[:2], rs, augmentation_function=prep.augment_imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f50e81cb-bfd6-4ac8-a36d-da6ca500c5f3",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5f59ef1d-0f95-4a14-a92d-327229a104a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b5bbe2fe-8e5b-4e69-a87d-81dcee513b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "tl_model = models.build_ResNet50_TL(\n",
    "    n_outputs,\n",
    "    resnet_inp_shape,\n",
    "    # base_last_layer=\"conv5_block3_out\",\n",
    "    # base_last_layer=\"conv5_block2_out\",\n",
    "    # base_last_layer=\"conv5_block1_out\",\n",
    "    base_last_layer=\"conv4_block6_out\",\n",
    "    # base_last_layer=\"conv4_block5_out\",\n",
    "    # base_last_layer=\"conv4_block4_out\",\n",
    "    # base_last_layer=\"conv4_block3_out\",\n",
    "    # base_last_layer=\"conv4_block2_out\",\n",
    "    # base_last_layer=\"conv4_block1_out\",\n",
    "    # base_last_layer=\"conv3_block4_out\",\n",
    "    # Switch to softmax once n_outputs > 1\n",
    "    output_act=\"sigmoid\",\n",
    "    base_model_trainable=False\n",
    ")\n",
    "# tl_model.compile(optimizer=Adam(), loss=BinaryCrossentropy(), metrics=[BinaryAccuracy()])\n",
    "tl_model.compile(optimizer=Adam(), loss=BinaryCrossentropy(), weighted_metrics=[BinaryAccuracy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "134be685-feda-4ef2-b1f3-e431dcf88233",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 128, 128, 3)]     0         \n",
      "_________________________________________________________________\n",
      "base_model (Functional)      (None, 8, 8, 1024)        8589184   \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 1025      \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 8,590,209\n",
      "Trainable params: 1,025\n",
      "Non-trainable params: 8,589,184\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tl_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "97b6dab5-1ecc-40f3-949e-caeea1ee2b1a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# tl_model.get_layer(\"base_model\").summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4a30cd0a-6cef-4e3b-b85a-b95be2cd08b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "es_callback = EarlyStopping(monitor=es_criterion, mode=es_mode, min_delta=es_min_delta, patience=es_patience)\n",
    "cp_callback = ModelCheckpoint(mcp_best_frozen_weights_file, monitor=mcp_criterion, mode=mcp_mode, save_best_only=mcp_best_only, save_weights_only=mcp_weights_only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c38e7b3e-8344-49f4-8c52-70d9ae017acd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "13/13 [==============================] - 16s 338ms/step - loss: 0.8241 - binary_accuracy: 0.4299 - val_loss: 0.6640 - val_binary_accuracy: 0.6055\n",
      "Epoch 2/50\n",
      "13/13 [==============================] - 5s 222ms/step - loss: 0.6653 - binary_accuracy: 0.5654 - val_loss: 0.6301 - val_binary_accuracy: 0.6187\n",
      "Epoch 3/50\n",
      "13/13 [==============================] - 5s 226ms/step - loss: 0.5944 - binary_accuracy: 0.6637 - val_loss: 0.5637 - val_binary_accuracy: 0.8097\n",
      "Epoch 4/50\n",
      "13/13 [==============================] - 4s 228ms/step - loss: 0.5881 - binary_accuracy: 0.7197 - val_loss: 0.5146 - val_binary_accuracy: 0.8768\n",
      "Epoch 5/50\n",
      "13/13 [==============================] - 4s 210ms/step - loss: 0.5239 - binary_accuracy: 0.7818 - val_loss: 0.5053 - val_binary_accuracy: 0.7741\n",
      "Epoch 6/50\n",
      "13/13 [==============================] - 4s 213ms/step - loss: 0.4974 - binary_accuracy: 0.7882 - val_loss: 0.4671 - val_binary_accuracy: 0.8087\n",
      "Epoch 7/50\n",
      "13/13 [==============================] - 4s 204ms/step - loss: 0.4480 - binary_accuracy: 0.8175 - val_loss: 0.4356 - val_binary_accuracy: 0.8049\n",
      "Epoch 8/50\n",
      "13/13 [==============================] - 4s 222ms/step - loss: 0.4459 - binary_accuracy: 0.8232 - val_loss: 0.4532 - val_binary_accuracy: 0.8065\n",
      "Epoch 9/50\n",
      "13/13 [==============================] - 4s 218ms/step - loss: 0.4268 - binary_accuracy: 0.8197 - val_loss: 0.4417 - val_binary_accuracy: 0.8080\n",
      "Epoch 10/50\n",
      "13/13 [==============================] - 4s 208ms/step - loss: 0.4270 - binary_accuracy: 0.8372 - val_loss: 0.4506 - val_binary_accuracy: 0.8324\n",
      "Epoch 11/50\n",
      "13/13 [==============================] - 4s 209ms/step - loss: 0.4251 - binary_accuracy: 0.8228 - val_loss: 0.4430 - val_binary_accuracy: 0.8037\n",
      "Epoch 12/50\n",
      "13/13 [==============================] - 4s 213ms/step - loss: 0.4231 - binary_accuracy: 0.7914 - val_loss: 0.4386 - val_binary_accuracy: 0.7595\n",
      "Epoch 13/50\n",
      "13/13 [==============================] - 4s 209ms/step - loss: 0.4116 - binary_accuracy: 0.8186 - val_loss: 0.4253 - val_binary_accuracy: 0.8209\n",
      "Epoch 14/50\n",
      "13/13 [==============================] - 4s 218ms/step - loss: 0.4113 - binary_accuracy: 0.8175 - val_loss: 0.4275 - val_binary_accuracy: 0.7907\n",
      "Epoch 15/50\n",
      "13/13 [==============================] - 4s 212ms/step - loss: 0.4040 - binary_accuracy: 0.8292 - val_loss: 0.4500 - val_binary_accuracy: 0.8143\n",
      "Epoch 16/50\n",
      "13/13 [==============================] - 4s 200ms/step - loss: 0.3889 - binary_accuracy: 0.8343 - val_loss: 0.3944 - val_binary_accuracy: 0.8115\n",
      "Epoch 17/50\n",
      "13/13 [==============================] - 4s 222ms/step - loss: 0.4020 - binary_accuracy: 0.8242 - val_loss: 0.4026 - val_binary_accuracy: 0.8361\n",
      "Epoch 18/50\n",
      "13/13 [==============================] - 5s 232ms/step - loss: 0.3845 - binary_accuracy: 0.8015 - val_loss: 0.4120 - val_binary_accuracy: 0.8286\n",
      "Epoch 19/50\n",
      "13/13 [==============================] - 5s 224ms/step - loss: 0.3756 - binary_accuracy: 0.8444 - val_loss: 0.4297 - val_binary_accuracy: 0.7872\n",
      "Epoch 20/50\n",
      "13/13 [==============================] - 4s 209ms/step - loss: 0.3702 - binary_accuracy: 0.8231 - val_loss: 0.4127 - val_binary_accuracy: 0.8429\n",
      "Epoch 21/50\n",
      "13/13 [==============================] - 5s 247ms/step - loss: 0.3778 - binary_accuracy: 0.8415 - val_loss: 0.4322 - val_binary_accuracy: 0.8157\n",
      "Epoch 22/50\n",
      "13/13 [==============================] - 4s 216ms/step - loss: 0.3735 - binary_accuracy: 0.8212 - val_loss: 0.4009 - val_binary_accuracy: 0.7972\n",
      "Epoch 23/50\n",
      "13/13 [==============================] - 4s 207ms/step - loss: 0.3722 - binary_accuracy: 0.8294 - val_loss: 0.4514 - val_binary_accuracy: 0.7926\n",
      "Epoch 24/50\n",
      "13/13 [==============================] - 4s 199ms/step - loss: 0.3717 - binary_accuracy: 0.8258 - val_loss: 0.4599 - val_binary_accuracy: 0.7624\n",
      "Epoch 25/50\n",
      "13/13 [==============================] - 4s 197ms/step - loss: 0.3648 - binary_accuracy: 0.8449 - val_loss: 0.4150 - val_binary_accuracy: 0.8194\n",
      "Epoch 26/50\n",
      "13/13 [==============================] - 4s 207ms/step - loss: 0.3606 - binary_accuracy: 0.8311 - val_loss: 0.4417 - val_binary_accuracy: 0.8209\n",
      "Epoch 27/50\n",
      "13/13 [==============================] - 5s 215ms/step - loss: 0.3635 - binary_accuracy: 0.8489 - val_loss: 0.4516 - val_binary_accuracy: 0.7917\n",
      "Epoch 28/50\n",
      "13/13 [==============================] - 4s 210ms/step - loss: 0.3536 - binary_accuracy: 0.8491 - val_loss: 0.4293 - val_binary_accuracy: 0.8073\n",
      "Epoch 29/50\n",
      "13/13 [==============================] - 4s 203ms/step - loss: 0.3592 - binary_accuracy: 0.8328 - val_loss: 0.3975 - val_binary_accuracy: 0.8220\n",
      "Epoch 30/50\n",
      "13/13 [==============================] - 4s 208ms/step - loss: 0.3473 - binary_accuracy: 0.8456 - val_loss: 0.4411 - val_binary_accuracy: 0.8121\n",
      "Epoch 31/50\n",
      "13/13 [==============================] - 4s 199ms/step - loss: 0.3540 - binary_accuracy: 0.8469 - val_loss: 0.4067 - val_binary_accuracy: 0.7793\n",
      "Epoch 32/50\n",
      "13/13 [==============================] - 4s 198ms/step - loss: 0.3700 - binary_accuracy: 0.8490 - val_loss: 0.3557 - val_binary_accuracy: 0.8246\n",
      "Epoch 33/50\n",
      "13/13 [==============================] - 4s 211ms/step - loss: 0.3740 - binary_accuracy: 0.8450 - val_loss: 0.4179 - val_binary_accuracy: 0.7926\n",
      "Epoch 34/50\n",
      "13/13 [==============================] - 4s 200ms/step - loss: 0.3843 - binary_accuracy: 0.8251 - val_loss: 0.4220 - val_binary_accuracy: 0.8270\n",
      "Epoch 35/50\n",
      "13/13 [==============================] - 4s 200ms/step - loss: 0.3502 - binary_accuracy: 0.8646 - val_loss: 0.4488 - val_binary_accuracy: 0.8058\n",
      "Epoch 36/50\n",
      "13/13 [==============================] - 4s 206ms/step - loss: 0.3377 - binary_accuracy: 0.8513 - val_loss: 0.4416 - val_binary_accuracy: 0.7926\n",
      "Epoch 37/50\n",
      "13/13 [==============================] - 4s 212ms/step - loss: 0.3480 - binary_accuracy: 0.8409 - val_loss: 0.4644 - val_binary_accuracy: 0.7889\n",
      "Epoch 38/50\n",
      "13/13 [==============================] - 4s 214ms/step - loss: 0.3397 - binary_accuracy: 0.8412 - val_loss: 0.4168 - val_binary_accuracy: 0.7946\n",
      "Epoch 39/50\n",
      "13/13 [==============================] - 4s 206ms/step - loss: 0.3429 - binary_accuracy: 0.8466 - val_loss: 0.3869 - val_binary_accuracy: 0.8546\n",
      "Epoch 40/50\n",
      "13/13 [==============================] - 4s 192ms/step - loss: 0.3351 - binary_accuracy: 0.8520 - val_loss: 0.4354 - val_binary_accuracy: 0.7672\n",
      "Epoch 41/50\n",
      "13/13 [==============================] - 4s 202ms/step - loss: 0.3448 - binary_accuracy: 0.8382 - val_loss: 0.4072 - val_binary_accuracy: 0.8314\n",
      "Epoch 42/50\n",
      "13/13 [==============================] - 4s 210ms/step - loss: 0.3404 - binary_accuracy: 0.8578 - val_loss: 0.4381 - val_binary_accuracy: 0.7908\n",
      "Epoch 43/50\n",
      "13/13 [==============================] - 4s 213ms/step - loss: 0.3280 - binary_accuracy: 0.8541 - val_loss: 0.3843 - val_binary_accuracy: 0.8274\n",
      "Epoch 44/50\n",
      "13/13 [==============================] - 4s 213ms/step - loss: 0.3545 - binary_accuracy: 0.8129 - val_loss: 0.4093 - val_binary_accuracy: 0.8037\n",
      "Epoch 45/50\n",
      "13/13 [==============================] - 4s 215ms/step - loss: 0.3414 - binary_accuracy: 0.8528 - val_loss: 0.4263 - val_binary_accuracy: 0.8073\n",
      "Epoch 46/50\n",
      "13/13 [==============================] - 4s 213ms/step - loss: 0.3499 - binary_accuracy: 0.8270 - val_loss: 0.3757 - val_binary_accuracy: 0.8611\n",
      "Epoch 47/50\n",
      "13/13 [==============================] - 4s 211ms/step - loss: 0.3434 - binary_accuracy: 0.8405 - val_loss: 0.4438 - val_binary_accuracy: 0.8016\n",
      "Epoch 48/50\n",
      "13/13 [==============================] - 5s 216ms/step - loss: 0.3174 - binary_accuracy: 0.8384 - val_loss: 0.4503 - val_binary_accuracy: 0.8183\n",
      "Epoch 49/50\n",
      "13/13 [==============================] - 5s 221ms/step - loss: 0.3326 - binary_accuracy: 0.8495 - val_loss: 0.4338 - val_binary_accuracy: 0.8209\n",
      "Epoch 50/50\n",
      "13/13 [==============================] - 4s 223ms/step - loss: 0.3363 - binary_accuracy: 0.8632 - val_loss: 0.4300 - val_binary_accuracy: 0.7846\n"
     ]
    }
   ],
   "source": [
    "h1 = tl_model.fit(\n",
    "    train_datagen,\n",
    "    validation_data=val_datagen,\n",
    "    epochs=frozen_epochs,\n",
    "    callbacks=[es_callback, cp_callback],\n",
    "    workers=n_cores\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b5b4515d-5967-4631-a496-1ae1931ab042",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31, 0.3556758463382721)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmin(h1.history[\"val_loss\"]), np.min(h1.history[\"val_loss\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "85cc9124-a9b3-48d2-acb6-2289349c5f43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 0.8768281936645508)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(h1.history[\"val_binary_accuracy\"]), np.max(h1.history[\"val_binary_accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d21a2e1-6fb0-4252-97b6-7f395a21aa98",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Load best frozen weights before fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f727e052-d9c1-4613-8582-d93c31e46047",
   "metadata": {},
   "outputs": [],
   "source": [
    "tl_model.load_weights(mcp_best_frozen_weights_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e04b9f7-0220-47e1-88a1-b375166403e7",
   "metadata": {},
   "source": [
    "# Train model (all layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "826188ac-9b5f-4e90-8d9f-2fcaeaa1a98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make base model trainable (leave layers in inference mode)\n",
    "models.toggle_TL_freeze(tl_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9fce61bd-18b7-43e0-96f9-a309c763888f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tl_model.compile(optimizer=Adam(learning_rate=fine_tune_lr), loss=BinaryCrossentropy(), metrics=[BinaryAccuracy()])\n",
    "tl_model.compile(optimizer=Adam(learning_rate=fine_tune_lr), loss=BinaryCrossentropy(), weighted_metrics=[BinaryAccuracy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ff63ccae-1830-4cda-ad44-a8bc1436562c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 128, 128, 3)]     0         \n",
      "_________________________________________________________________\n",
      "base_model (Functional)      (None, 8, 8, 1024)        8589184   \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 1025      \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 8,590,209\n",
      "Trainable params: 8,559,617\n",
      "Non-trainable params: 30,592\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tl_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4bc0da73-0193-4e18-bc4c-f84d86e17a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "es_callback = EarlyStopping(monitor=es_criterion, mode=es_mode, min_delta=es_min_delta, patience=es_patience)\n",
    "cp_callback = ModelCheckpoint(mcp_best_finetune_weights_file, monitor=mcp_criterion, mode=mcp_mode, save_best_only=mcp_best_only, save_weights_only=mcp_weights_only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "05c2c008-c5fe-473f-a209-9da1e56b64b4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "13/13 [==============================] - 10s 279ms/step - loss: 0.3595 - binary_accuracy: 0.8387 - val_loss: 0.3829 - val_binary_accuracy: 0.8324\n",
      "Epoch 2/50\n",
      "13/13 [==============================] - 2s 186ms/step - loss: 0.3397 - binary_accuracy: 0.8421 - val_loss: 0.4181 - val_binary_accuracy: 0.7793\n",
      "Epoch 3/50\n",
      "13/13 [==============================] - 2s 184ms/step - loss: 0.2987 - binary_accuracy: 0.8460 - val_loss: 0.3893 - val_binary_accuracy: 0.7633\n",
      "Epoch 4/50\n",
      "13/13 [==============================] - 2s 184ms/step - loss: 0.3096 - binary_accuracy: 0.8444 - val_loss: 0.4807 - val_binary_accuracy: 0.7888\n",
      "Epoch 5/50\n",
      "13/13 [==============================] - 2s 185ms/step - loss: 0.2814 - binary_accuracy: 0.8803 - val_loss: 0.4493 - val_binary_accuracy: 0.7735\n",
      "Epoch 6/50\n",
      "13/13 [==============================] - 2s 183ms/step - loss: 0.2922 - binary_accuracy: 0.8756 - val_loss: 0.3650 - val_binary_accuracy: 0.8125\n",
      "Epoch 7/50\n",
      "13/13 [==============================] - 2s 184ms/step - loss: 0.2662 - binary_accuracy: 0.8883 - val_loss: 0.4443 - val_binary_accuracy: 0.7735\n",
      "Epoch 8/50\n",
      "13/13 [==============================] - 2s 182ms/step - loss: 0.2844 - binary_accuracy: 0.8729 - val_loss: 0.4787 - val_binary_accuracy: 0.8197\n",
      "Epoch 9/50\n",
      "13/13 [==============================] - 2s 185ms/step - loss: 0.2673 - binary_accuracy: 0.8839 - val_loss: 0.4239 - val_binary_accuracy: 0.8207\n",
      "Epoch 10/50\n",
      "13/13 [==============================] - 2s 182ms/step - loss: 0.2692 - binary_accuracy: 0.8750 - val_loss: 0.3945 - val_binary_accuracy: 0.8514\n",
      "Epoch 11/50\n",
      "13/13 [==============================] - 2s 183ms/step - loss: 0.2364 - binary_accuracy: 0.9096 - val_loss: 0.4095 - val_binary_accuracy: 0.8509\n",
      "Epoch 12/50\n",
      "13/13 [==============================] - 2s 184ms/step - loss: 0.2732 - binary_accuracy: 0.8880 - val_loss: 0.4871 - val_binary_accuracy: 0.8197\n",
      "Epoch 13/50\n",
      "13/13 [==============================] - 2s 184ms/step - loss: 0.2367 - binary_accuracy: 0.8916 - val_loss: 0.3989 - val_binary_accuracy: 0.8207\n",
      "Epoch 14/50\n",
      "13/13 [==============================] - 2s 182ms/step - loss: 0.2123 - binary_accuracy: 0.9113 - val_loss: 0.3854 - val_binary_accuracy: 0.8068\n",
      "Epoch 15/50\n",
      "13/13 [==============================] - 2s 184ms/step - loss: 0.2009 - binary_accuracy: 0.9263 - val_loss: 0.4445 - val_binary_accuracy: 0.8481\n",
      "Epoch 16/50\n",
      "13/13 [==============================] - 2s 185ms/step - loss: 0.1857 - binary_accuracy: 0.9189 - val_loss: 0.4015 - val_binary_accuracy: 0.7899\n",
      "Epoch 17/50\n",
      "13/13 [==============================] - 3s 211ms/step - loss: 0.1827 - binary_accuracy: 0.9363 - val_loss: 0.4369 - val_binary_accuracy: 0.8518\n",
      "Epoch 18/50\n",
      "13/13 [==============================] - 2s 184ms/step - loss: 0.1831 - binary_accuracy: 0.9314 - val_loss: 0.3849 - val_binary_accuracy: 0.7870\n",
      "Epoch 19/50\n",
      "13/13 [==============================] - 2s 185ms/step - loss: 0.1650 - binary_accuracy: 0.9331 - val_loss: 0.4462 - val_binary_accuracy: 0.8493\n",
      "Epoch 20/50\n",
      "13/13 [==============================] - 2s 186ms/step - loss: 0.1489 - binary_accuracy: 0.9502 - val_loss: 0.4955 - val_binary_accuracy: 0.7917\n",
      "Epoch 21/50\n",
      "13/13 [==============================] - 2s 186ms/step - loss: 0.1765 - binary_accuracy: 0.9436 - val_loss: 0.4442 - val_binary_accuracy: 0.8583\n",
      "Epoch 22/50\n",
      "13/13 [==============================] - 2s 186ms/step - loss: 0.1741 - binary_accuracy: 0.9391 - val_loss: 0.4568 - val_binary_accuracy: 0.8705\n",
      "Epoch 23/50\n",
      "13/13 [==============================] - 2s 184ms/step - loss: 0.1285 - binary_accuracy: 0.9645 - val_loss: 0.4684 - val_binary_accuracy: 0.8578\n",
      "Epoch 24/50\n",
      "13/13 [==============================] - 2s 188ms/step - loss: 0.1348 - binary_accuracy: 0.9511 - val_loss: 0.5462 - val_binary_accuracy: 0.8191\n",
      "Epoch 25/50\n",
      "13/13 [==============================] - 2s 186ms/step - loss: 0.1075 - binary_accuracy: 0.9721 - val_loss: 0.5588 - val_binary_accuracy: 0.7681\n",
      "Epoch 26/50\n",
      "13/13 [==============================] - 2s 187ms/step - loss: 0.0973 - binary_accuracy: 0.9698 - val_loss: 0.3095 - val_binary_accuracy: 0.8617\n",
      "Epoch 27/50\n",
      "13/13 [==============================] - 3s 193ms/step - loss: 0.0993 - binary_accuracy: 0.9611 - val_loss: 0.5025 - val_binary_accuracy: 0.8397\n",
      "Epoch 28/50\n",
      "13/13 [==============================] - 2s 188ms/step - loss: 0.1004 - binary_accuracy: 0.9643 - val_loss: 0.5217 - val_binary_accuracy: 0.8361\n",
      "Epoch 29/50\n",
      "13/13 [==============================] - 2s 186ms/step - loss: 0.0683 - binary_accuracy: 0.9741 - val_loss: 0.6521 - val_binary_accuracy: 0.8097\n",
      "Epoch 30/50\n",
      "13/13 [==============================] - 3s 191ms/step - loss: 0.0837 - binary_accuracy: 0.9762 - val_loss: 0.6382 - val_binary_accuracy: 0.7985\n",
      "Epoch 31/50\n",
      "13/13 [==============================] - 2s 189ms/step - loss: 0.0975 - binary_accuracy: 0.9655 - val_loss: 0.7230 - val_binary_accuracy: 0.7899\n",
      "Epoch 32/50\n",
      "13/13 [==============================] - 2s 188ms/step - loss: 0.0898 - binary_accuracy: 0.9644 - val_loss: 0.3509 - val_binary_accuracy: 0.8421\n",
      "Epoch 33/50\n",
      "13/13 [==============================] - 3s 190ms/step - loss: 0.0619 - binary_accuracy: 0.9782 - val_loss: 0.7359 - val_binary_accuracy: 0.7600\n",
      "Epoch 34/50\n",
      "13/13 [==============================] - 2s 189ms/step - loss: 0.0660 - binary_accuracy: 0.9837 - val_loss: 0.8252 - val_binary_accuracy: 0.7982\n",
      "Epoch 35/50\n",
      "13/13 [==============================] - 3s 193ms/step - loss: 0.0644 - binary_accuracy: 0.9758 - val_loss: 0.6177 - val_binary_accuracy: 0.8614\n",
      "Epoch 36/50\n",
      "13/13 [==============================] - 2s 188ms/step - loss: 0.0886 - binary_accuracy: 0.9787 - val_loss: 0.7051 - val_binary_accuracy: 0.7803\n",
      "Epoch 37/50\n",
      "13/13 [==============================] - 3s 189ms/step - loss: 0.0634 - binary_accuracy: 0.9693 - val_loss: 0.5179 - val_binary_accuracy: 0.8768\n",
      "Epoch 38/50\n",
      "13/13 [==============================] - 3s 189ms/step - loss: 0.1497 - binary_accuracy: 0.9410 - val_loss: 0.6416 - val_binary_accuracy: 0.8220\n",
      "Epoch 39/50\n",
      "13/13 [==============================] - 3s 190ms/step - loss: 0.0765 - binary_accuracy: 0.9709 - val_loss: 0.5682 - val_binary_accuracy: 0.8518\n",
      "Epoch 40/50\n",
      "13/13 [==============================] - 3s 195ms/step - loss: 0.0609 - binary_accuracy: 0.9824 - val_loss: 0.4139 - val_binary_accuracy: 0.8052\n",
      "Epoch 41/50\n",
      "13/13 [==============================] - 3s 188ms/step - loss: 0.0434 - binary_accuracy: 0.9926 - val_loss: 0.5498 - val_binary_accuracy: 0.8804\n",
      "Epoch 42/50\n",
      "13/13 [==============================] - 3s 191ms/step - loss: 0.0419 - binary_accuracy: 0.9863 - val_loss: 0.7978 - val_binary_accuracy: 0.7695\n",
      "Epoch 43/50\n",
      "13/13 [==============================] - 3s 189ms/step - loss: 0.0534 - binary_accuracy: 0.9920 - val_loss: 0.6256 - val_binary_accuracy: 0.8324\n",
      "Epoch 44/50\n",
      "13/13 [==============================] - 3s 192ms/step - loss: 0.0498 - binary_accuracy: 0.9802 - val_loss: 0.7857 - val_binary_accuracy: 0.7917\n",
      "Epoch 45/50\n",
      "13/13 [==============================] - 3s 192ms/step - loss: 0.0306 - binary_accuracy: 0.9941 - val_loss: 0.7153 - val_binary_accuracy: 0.8068\n",
      "Epoch 46/50\n",
      "13/13 [==============================] - 3s 192ms/step - loss: 0.0263 - binary_accuracy: 0.9956 - val_loss: 0.8705 - val_binary_accuracy: 0.8201\n",
      "Epoch 47/50\n",
      "13/13 [==============================] - 3s 198ms/step - loss: 0.0533 - binary_accuracy: 0.9869 - val_loss: 0.7472 - val_binary_accuracy: 0.8390\n",
      "Epoch 48/50\n",
      "13/13 [==============================] - 3s 194ms/step - loss: 0.0309 - binary_accuracy: 0.9897 - val_loss: 1.2279 - val_binary_accuracy: 0.7752\n",
      "Epoch 49/50\n",
      "13/13 [==============================] - 3s 199ms/step - loss: 0.0316 - binary_accuracy: 0.9877 - val_loss: 0.7747 - val_binary_accuracy: 0.8097\n",
      "Epoch 50/50\n",
      "13/13 [==============================] - 3s 195ms/step - loss: 0.0186 - binary_accuracy: 0.9941 - val_loss: 0.8289 - val_binary_accuracy: 0.7917\n"
     ]
    }
   ],
   "source": [
    "h2 = tl_model.fit(\n",
    "    train_datagen,\n",
    "    validation_data=val_datagen,\n",
    "    epochs=fine_tune_epochs,\n",
    "    callbacks=[es_callback, cp_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "010da2d1-dcef-47c8-8011-73bbf31c5b0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 0.3095390498638153)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmin(h2.history[\"val_loss\"]), np.min(h2.history[\"val_loss\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1d04b350-b75d-43ed-bfc4-a02f09c5bb45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 0.8804331421852112)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(h2.history[\"val_binary_accuracy\"]), np.max(h2.history[\"val_binary_accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51be6fcc-fc03-4ee3-9304-0227c8a48054",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

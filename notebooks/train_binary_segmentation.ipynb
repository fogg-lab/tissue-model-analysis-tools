{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c317cd67",
   "metadata": {},
   "source": [
    "# Train Binary Segmentation\n",
    "## Instructions to run\n",
    "- Modify the configuration variables in the [Constants](#constants) section and the [Training configuration](#training-configuration) section as needed.\n",
    "- Customize the image transformations pipeline in the [Image transformations/augmentation](#image-transformations-augmentation) section.\n",
    "- Run all the cells\n",
    "- *Note*: This notebook is not ideal for the free Google Colab runtime, as it is prone to disconnecting during long training sessions. It is recommended to run this notebook on an HPC cluster, on a computer with an NVIDIA (CUDA-capable) GPU, or with Colab Pro."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "318725ae",
   "metadata": {},
   "source": [
    "## Package imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ae6a771-9e99-4deb-ae5d-04bc3a9c020a",
   "metadata": {
    "id": "9ae6a771-9e99-4deb-ae5d-04bc3a9c020a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/bean/fl_tissue_model_tools\n",
      "Available GPUS:\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import math\n",
    "import os\n",
    "import requests\n",
    "from zipfile import ZipFile\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import albumentations as A\n",
    "if not hasattr(Image, 'Resampling'):\n",
    "    Image.Resampling = Image\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.config import list_physical_devices\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard, ReduceLROnPlateau\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.utils import custom_object_scope\n",
    "\n",
    "from fl_tissue_model_tools.transforms import get_elastic_dual_transform\n",
    "from fl_tissue_model_tools.preprocessing import get_batch_augmentor\n",
    "from fl_tissue_model_tools import models, models_util\n",
    "from fl_tissue_model_tools.helper import get_img_mask_paths\n",
    "\n",
    "# Make sure TensorFlow is using GPU - print out the available GPUs\n",
    "available_gpus = list_physical_devices('GPU')\n",
    "if len(available_gpus) == 0:\n",
    "    print(\"WARNING: TensorFlow isn't using a GPU.\")\n",
    "else:\n",
    "    print(f\"Available GPUS:\\n{available_gpus}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7ccdbfe1-1960-4f5d-8959-835debf0d104",
   "metadata": {},
   "source": [
    "<a name=\"constants\"></a>\n",
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d71c54a-2fdc-4ae4-806a-c6541996af4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dir = \"train_binary_segmentation\"\n",
    "\n",
    "images_dir = os.path.join(training_dir, \"images\")\n",
    "labels_dir = os.path.join(training_dir, \"masks\")\n",
    "\n",
    "rand_seed = 1234\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "# size of the random crop window, cannot be larger than the image size\n",
    "crop_window = (512, 512)\n",
    "\n",
    "# model input shape. cropped images/masks are resampled to this shape\n",
    "# target_shape must be divisible by 32, and must be square if using the patch-blending segmentor\n",
    "target_shape = (256, 256)\n",
    "#target_shape = crop_window     # uncomment to disable resizing the crops\n",
    "\n",
    "checkpoint_save_path = os.path.join(training_dir, \"checkpoints\")\n",
    "\n",
    "# number of times to iterate over the samples each epoch\n",
    "# We can set this pretty high without overfitting since we sample crops from high-res images,\n",
    "#  and apply heavy augmentations including geometric transformations.\n",
    "repeat_dset_n_times = 50\n",
    "\n",
    "# save training logs for tensorboard\n",
    "log_save_path = os.path.join(training_dir, \"logs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ebebc19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the training directory if it doesn't exist\n",
    "Path(training_dir).mkdir(exist_ok=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b0edd537",
   "metadata": {},
   "source": [
    "### Hyperparameter search space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc1e605",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_counts_options = [\n",
    "    (16, 32, 64, 128),\n",
    "    (32, 64, 128, 256),\n",
    "    (64, 128, 256, 512)\n",
    "]\n",
    "\n",
    "# Scale learning rate options linearly according to batch size (stays as-is when batch size is 16)\n",
    "hp_search_initial_lr_options = [1e-4, 2.5e-4, 5e-4, 1e-3, 2.5e-3, 5e-3, 1e-2]\n",
    "hp_search_initial_lr_options = np.array(hp_search_initial_lr_options) * batch_size/16"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f4ad8add",
   "metadata": {},
   "source": [
    "## Download demo training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f260ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"branching_training_data.zip\"\n",
    "url = f\"https://github.com/fogg-lab/tissue-model-analysis-tools/raw/branching-script-update/sample_data/{filename}\"\n",
    "data = requests.get(url).content\n",
    "archive_save_path = os.path.join(training_dir, filename)\n",
    "open(archive_save_path, 'wb').write(data)\n",
    "\n",
    "# Extract the archive\n",
    "with ZipFile(archive_save_path, 'r') as data_archive:\n",
    "    data_archive.extractall(training_dir)\n",
    "\n",
    "# Delete the archive\n",
    "os.remove(archive_save_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ce4d7255",
   "metadata": {},
   "source": [
    "# Validate data paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec94713",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_mask_paths = get_img_mask_paths(images_dir, labels_dir)\n",
    "img_paths, mask_paths = zip(*image_mask_paths)\n",
    "\n",
    "print(f\"Found {len(image_mask_paths)} image/label pairs\")\n",
    "\n",
    "for img_path, mask_path in image_mask_paths:\n",
    "    image = cv2.imread(img_path, 0)\n",
    "    mask = cv2.imread(mask_path, 0)\n",
    "\n",
    "    assert image.shape == mask.shape, (\n",
    "        f\"Image {img_path} and mask {mask_path} have different shapes: {image.shape} vs {mask.shape}\"\n",
    "    )\n",
    "\n",
    "    if np.unique(mask).tolist() not in ([0], [255], [0, 255]):\n",
    "        print(f\"Mask {mask_path} has unexpected values: {np.unique(mask)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "466087fc-c514-4865-aa51-7335f86d5c5f",
   "metadata": {},
   "source": [
    "## Data pipeline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9b4c5102-39e4-4927-9b4b-bc5a3f11fd0b",
   "metadata": {},
   "source": [
    "### Get training and validation image paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd7dc19-663c-4848-8e4e-d9e0e561a791",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_val = int(len(img_paths) * 0.2)\n",
    "\n",
    "# Shuffle the data image/mask keeping pairs together\n",
    "\n",
    "#indices = np.random.permutation(len(img_paths))    # non-seeded random shuffle\n",
    "rs = np.random.RandomState(seed=rand_seed)\n",
    "indices = rs.permutation(len(img_paths))\n",
    "\n",
    "img_paths = [img_paths[i] for i in indices]\n",
    "mask_paths = [mask_paths[i] for i in indices]\n",
    "\n",
    "train_img_paths = img_paths[: -n_val]\n",
    "train_mask_paths = mask_paths[:-n_val]\n",
    "\n",
    "val_img_paths = img_paths[-n_val:]\n",
    "val_mask_paths = mask_paths[-n_val:]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "390e6efa-dc2d-4452-b44a-5a45126b335b",
   "metadata": {},
   "source": [
    "### Compute sample weights & mean/std for training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2afa6707-9d2e-44b3-a8ba-c953d8a87f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_labels = models_util.load_y(train_mask_paths)\n",
    "\n",
    "n_fg = np.sum(y_train_labels == 1)\n",
    "n_bg = np.sum(y_train_labels == 0)\n",
    "fg_weight = float(n_fg + n_bg) / (2.0 * n_fg)\n",
    "bg_weight = float(n_fg + n_bg) / (2.0 * n_bg)\n",
    "sample_weights = {0: bg_weight, 1: fg_weight}\n",
    "sample_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e99584",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the mean and std of the training set images\n",
    "x_train_imgs = models_util.load_x(img_paths)\n",
    "im_mean = np.mean(x_train_imgs)\n",
    "im_std = np.std(x_train_imgs)\n",
    "\n",
    "im_mean, im_std"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d35bc464",
   "metadata": {},
   "source": [
    "### Image transformations/augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e296e5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_resizer(ds_shape):\n",
    "    def ds_im_mask(image, mask):\n",
    "        \"\"\"Downscale image with Lanczos interpolation and mask with nearest neighbor\"\"\"\n",
    "        image = cv2.resize(image, ds_shape, interpolation=cv2.INTER_LANCZOS4)\n",
    "        mask = np.array(Image.fromarray(mask).resize(ds_shape, resample=Image.Resampling.NEAREST))\n",
    "        return {'image': image, 'mask': mask}\n",
    "    return ds_im_mask\n",
    "\n",
    "def get_normalizer(mean, std):\n",
    "    def norm_im(image, mask):\n",
    "        \"\"\"Normalize image with mean and std of training set images\"\"\"\n",
    "        image = ((image - mean) / std).astype(np.float32)\n",
    "        return {'image': image, 'mask': mask}\n",
    "    return norm_im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c879dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = train_transforms = [\n",
    "    A.Compose([\n",
    "        A.Rotate(p=0.5, border_mode=cv2.BORDER_CONSTANT, value=0, mask_value=0),\n",
    "        A.RandomCrop(height=crop_window[0], width=crop_window[1]),\n",
    "        A.Flip(p=0.5),\n",
    "        A.RandomBrightnessContrast(p=0.7),\n",
    "        A.OneOf([\n",
    "                A.MultiplicativeNoise(p=0.5),\n",
    "                A.AdvancedBlur(p=0.5)\n",
    "        ], p=0.8),\n",
    "    ]),     # Albumentations pipeline\n",
    "    get_elastic_dual_transform(p=0.85),\n",
    "    get_resizer(target_shape),\n",
    "    get_normalizer(im_mean, im_std)\n",
    "]\n",
    "\n",
    "val_transforms = [\n",
    "    A.Compose([\n",
    "        A.RandomCrop(height=crop_window[0], width=crop_window[1]),\n",
    "        A.Flip(p=0.5),\n",
    "        A.RandomRotate90(p=0.5)\n",
    "    ]),\n",
    "    get_resizer(target_shape),\n",
    "    get_normalizer(im_mean, im_std)\n",
    "]\n",
    "\n",
    "train_augmentor = get_batch_augmentor(train_transforms)\n",
    "val_augmentor = get_batch_augmentor(val_transforms)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9f2e0097",
   "metadata": {},
   "source": [
    "### Create the training and validation data generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765af584-10bf-426a-99c5-5121c7fedf9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rs = np.random.RandomState(seed=rand_seed)\n",
    "\n",
    "train_gen = models_util.BinaryMaskSequence(\n",
    "    batch_size, train_img_paths, train_mask_paths, rs,\n",
    "    models_util.load_x, models_util.load_y, augmentation_function=train_augmentor,\n",
    "    sample_weights=sample_weights, repeat_n_times=repeat_dset_n_times, shuffle=True\n",
    ")\n",
    "\n",
    "val_gen = models_util.BinaryMaskSequence(\n",
    "    batch_size, val_img_paths, val_mask_paths,\n",
    "    rs, models_util.load_x, models_util.load_y, augmentation_function=val_augmentor,\n",
    "    sample_weights=sample_weights, repeat_n_times=repeat_dset_n_times, shuffle=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d91b7579",
   "metadata": {},
   "source": [
    "### Test the training generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee861e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, _ = train_gen[1]\n",
    "for i in range(batch_size):\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    ax[0].imshow(X[i][:,:,0], cmap='gray')\n",
    "    ax[1].imshow(y[i][:,:,0], cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e912a0bc",
   "metadata": {},
   "source": [
    "### Test the validation generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a43f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, _ = val_gen[1]\n",
    "for i in range(batch_size):\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    ax[0].imshow(X[i][:,:,0], cmap='gray')\n",
    "    ax[1].imshow(y[i][:,:,0], cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "63046361",
   "metadata": {},
   "source": [
    "## Training configuration"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "065725c4",
   "metadata": {},
   "source": [
    "*We'll warm up to the initial learning rate and either use a cyclic schedule or reduce it when val_loss plateaus.*\n",
    "\n",
    "Parameters you should customize:\n",
    "- `n_epochs`\n",
    "- `hp_search_epochs`\n",
    "- `weight_decay`\n",
    "\n",
    "Extra parameters you should customize for cyclic schedule:\n",
    "- `cyclic_lr_mult`\n",
    "- `num_cycles`\n",
    "\n",
    "Extra parameters you should customize for reduce lr on plateau:\n",
    "- `lr_patience`\n",
    "- `lr_reduction_factor`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b725daec",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 50\n",
    "hp_search_epochs = n_epochs // 7\n",
    "\n",
    "epoch_len = math.ceil(((len(train_img_paths)) * train_gen.repeat_n_times) / batch_size)\n",
    "linear_warmup_steps = epoch_len\n",
    "\n",
    "# use_cosine_decay_restarts: true to use a cyclic lr schedule, false for ReduceLROnPlateau\n",
    "use_cosine_decay_restarts = True\n",
    "\n",
    "# get optimizer options for grid search (vary the initial learning rate)\n",
    "hp_search_optimizer_options = []\n",
    "for initial_lr in hp_search_initial_lr_options:\n",
    "    if use_cosine_decay_restarts:\n",
    "        # cosine annealing parameters - timed so the last cycle ends at the end of training\n",
    "        cycle_lr_mult = 0.5         # decrease initial lr at the end of each cycle (m_mul)\n",
    "        num_cycles = 3              # number of full cycles\n",
    "\n",
    "        # figure out what the first_decay_steps should be\n",
    "        # start counting after the warmup steps\n",
    "        total_steps = epoch_len * n_epochs - linear_warmup_steps\n",
    "\n",
    "        # round up and add 1 to prevent an extra restart at the end\n",
    "        first_decay_steps = math.ceil(total_steps / (2**num_cycles - 1)) + 1\n",
    "\n",
    "        learning_rate = optimizers.schedules.CosineDecayRestarts(\n",
    "            initial_learning_rate=initial_lr,\n",
    "            first_decay_steps=first_decay_steps,\n",
    "            t_mul=2.0,  # our first_decay_steps calculation assumes t_mul=2\n",
    "            m_mul=cycle_lr_mult\n",
    "        )\n",
    "        learning_rate = optimizers.serialize(learning_rate)\n",
    "    else:\n",
    "        # patience: number of epochs with no improvement after which learning rate will be reduced\n",
    "        patience = 4\n",
    "        lr_reduction_factor = 0.5\n",
    "        learning_rate = initial_lr\n",
    "        reduce_lr = ReduceLROnPlateau(\n",
    "            monitor='val_loss',\n",
    "            factor=lr_reduction_factor,\n",
    "            patience=patience,\n",
    "            verbose=1,\n",
    "            mode='min'\n",
    "        )\n",
    "\n",
    "    lr_schedule = models_util.WarmupSchedule(warmup_steps=linear_warmup_steps,\n",
    "                                             after_warmup_lr=learning_rate)\n",
    "\n",
    "    weight_decay = 1e-4     # weight decay for AdamW\n",
    "\n",
    "    optimizer = optimizers.experimental.AdamW(learning_rate=lr_schedule, weight_decay=weight_decay)\n",
    "    optimizer_config = optimizers.serialize(optimizer)\n",
    "\n",
    "    hp_search_optimizer_options.append(optimizer_config)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "006f30b5-b1a4-4363-b245-3b3c4fda12e9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Hyperparameter search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8eac977-0d95-49b4-9a1d-bb53d82ee237",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "metrics=[models_util.mean_iou_coef_factory(thresh=0.5)]\n",
    "loss = BinaryCrossentropy()\n",
    "callbacks = [] if use_cosine_decay_restarts else [reduce_lr]\n",
    "\n",
    "gs = models.UNetXceptionGridSearch(\n",
    "    save_dir=\"unet_grid_search\",\n",
    "    filter_counts_options=filter_counts_options,\n",
    "    n_outputs=1,\n",
    "    img_shape=target_shape,\n",
    "    optimizer_cfg_options=hp_search_optimizer_options,\n",
    "    loss=loss,\n",
    "    output_act=\"sigmoid\",\n",
    "    metrics=metrics,\n",
    "    callbacks=callbacks\n",
    ")\n",
    "\n",
    "with custom_object_scope({'WarmupSchedule': models_util.WarmupSchedule}):\n",
    "    gs.search(\n",
    "        \"mean_iou_coef\",\n",
    "        \"max\",\n",
    "        train_gen,\n",
    "        search_verbose=True,\n",
    "        validation_data=val_gen,\n",
    "        epochs=hp_search_epochs\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc4876b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the best learning rate schedule\n",
    "with custom_object_scope({'WarmupSchedule': models_util.WarmupSchedule}):\n",
    "    best_lr_schedule = gs.best_optimizer_cfg['config']['learning_rate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090e4792",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the best hyperparameters\n",
    "print(\"Best filter counts: \", gs.best_filter_counts)\n",
    "print(\"Best optimizer: \", gs.best_optimizer_cfg)\n",
    "print(\"Best initial learning rate: \", best_lr_schedule(linear_warmup_steps))\n",
    "print(\"Best score: \", gs.best_score)\n",
    "print(\"Best score index: \", gs.best_score_idx)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9d8a2607",
   "metadata": {},
   "source": [
    "### Plot the best learning rate schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33873419",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If ReduceLROnPlateau is used, possible LR reductions after the warmup period are not plotted\n",
    "n_steps = epoch_len * n_epochs\n",
    "lr_each_step = [best_lr_schedule(i) for i in range(n_steps)]\n",
    "epoch_each_step = np.arange(1, n_steps+1) / epoch_len\n",
    "plt.plot(epoch_each_step, lr_each_step)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Learning rate')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d94c758d",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5bd07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "\n",
    "with custom_object_scope({'WarmupSchedule': models.WarmupSchedule}):\n",
    "    optimizer = optimizers.deserialize(optimizer_config)\n",
    "\n",
    "model = models.build_UNetXception(1, target_shape, filter_counts=gs.best_filter_counts,\n",
    "                                  output_act=\"sigmoid\")\n",
    "\n",
    "metrics=[models.models_util.mean_iou_coef_factory(thresh=0.5)]\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=BinaryCrossentropy(), metrics=metrics)\n",
    "\n",
    "callbacks = [\n",
    "    ModelCheckpoint(checkpoint_save_path, save_best_only=True, save_weights_only=True),\n",
    "    TensorBoard(log_dir=log_save_path, histogram_freq=1)\n",
    "]\n",
    "\n",
    "callbacks = callbacks if use_cosine_decay_restarts else callbacks + [reduce_lr]\n",
    "\n",
    "h = model.fit(train_gen, validation_data=val_gen, epochs=n_epochs, callbacks=callbacks)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1511ba11-a4bc-49c5-9681-28f174643cb8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Try out the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f1fac3-608f-4b47-a5af-1cc10e0bf418",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_batch_num = 0\n",
    "val_x, val_y, _ = val_gen[val_batch_num]\n",
    "preds = model.predict(val_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517e3fa4-05ca-41d2-86d6-4c93489a3bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample_idx in range(0, batch_size):\n",
    "    image = val_x[sample_idx]\n",
    "    ground_truth = val_y[sample_idx]\n",
    "    prediction = preds[sample_idx]\n",
    "    fig, ax = plt.subplots(1, 4, figsize=(20, 5))\n",
    "    ax[0].imshow(image[:,:,0], cmap='gray')\n",
    "    ax[0].set_title(\"Image\")\n",
    "    ax[1].imshow(ground_truth[:,:,0], cmap='gray')\n",
    "    ax[1].set_title(\"True Segmentation\")\n",
    "    ax[2].imshow(prediction[:,:,0], cmap='gray')\n",
    "    ax[2].set_title(\"Prediction\")\n",
    "    ax[3].imshow(np.greater(prediction, 0.5)[:,:,0], cmap='gray')\n",
    "    ax[3].set_title(\"Predicted Segmentation\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d912494a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create patch segmentor config and save it\n",
    "downsample_ratio = np.divide(target_shape, crop_window)\n",
    "checkpoint_file = Path(checkpoint_save_path) / \"best_model.h5\"\n",
    "filter_counts = gs.best_filter_counts\n",
    "cfg = {\n",
    "    \"patch_shape\": crop_window,\n",
    "    \"checkpoint_file\": checkpoint_file,\n",
    "    \"filter_counts\": filter_counts,\n",
    "    \"ds_ratio\": downsample_ratio,\n",
    "    \"norm_mean\": im_mean,\n",
    "    \"norm_std\": im_std,\n",
    "    \"channels\": 1\n",
    "}\n",
    "models_util.save_unet_patch_segmentor_cfg(cfg)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "oxford_pets_v1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "tissue-model-analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "078c777ce772c045090e14aa3dbc9eaccd92c36b19b8f6c12088b63ee53c2db9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
